<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Graphical and Latent Variable Modeling</title>
  <meta name="description" content="Structural Equation Modeling: This document focuses on structural equation modeling. It is conceptually based, and tries to generalize beyond the standard SEM treatment. It is has special emphasis on the lavaan package. It will continue to be a work in progress, particularly the sections after the SEM chapter. Topics include: graphical models, including path analysis, bayesian networks, and network analysis, mediation, moderation, latent variable models, including principal components analysis and ‘factor analysis’, measurement models, structural equation models, mixture models, growth curves. Topics I hope to provide overviews of in the future include other latent variable techniques and extensions such as IRT, collaborative filtering/recommender systems, hidden markov models, multi-group models etc.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Graphical and Latent Variable Modeling" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/docs/sem/" />
  <meta property="og:image" content="https://m-clark.github.io/docs/sem/img/198R_1.png" />
  <meta property="og:description" content="Structural Equation Modeling: This document focuses on structural equation modeling. It is conceptually based, and tries to generalize beyond the standard SEM treatment. It is has special emphasis on the lavaan package. It will continue to be a work in progress, particularly the sections after the SEM chapter. Topics include: graphical models, including path analysis, bayesian networks, and network analysis, mediation, moderation, latent variable models, including principal components analysis and ‘factor analysis’, measurement models, structural equation models, mixture models, growth curves. Topics I hope to provide overviews of in the future include other latent variable techniques and extensions such as IRT, collaborative filtering/recommender systems, hidden markov models, multi-group models etc." />
  <meta name="github-repo" content="m-clark/sem/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Graphical and Latent Variable Modeling" />
  
  <meta name="twitter:description" content="Structural Equation Modeling: This document focuses on structural equation modeling. It is conceptually based, and tries to generalize beyond the standard SEM treatment. It is has special emphasis on the lavaan package. It will continue to be a work in progress, particularly the sections after the SEM chapter. Topics include: graphical models, including path analysis, bayesian networks, and network analysis, mediation, moderation, latent variable models, including principal components analysis and ‘factor analysis’, measurement models, structural equation models, mixture models, growth curves. Topics I hope to provide overviews of in the future include other latent variable techniques and extensions such as IRT, collaborative filtering/recommender systems, hidden markov models, multi-group models etc." />
  <meta name="twitter:image" content="https://m-clark.github.io/docs/sem/img/198R_1.png" />



<meta name="date" content="2018-02-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction-to-r.html">
<link rel="next" href="latent-variables-1.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-0.9.2/grViz.js"></script>
<script src="libs/d3-3.5.3/./d3.min.js"></script>
<link href="libs/d3heatmapcore-0.0.0/heatmapcore.css" rel="stylesheet" />
<script src="libs/d3heatmapcore-0.0.0/heatmapcore.js"></script>
<script src="libs/d3-tip-0.6.6/index.js"></script>
<script src="libs/d3heatmap-binding-0.6.1.1/d3heatmap.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.2/visNetwork.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/book.css" type="text/css" />
<link rel="stylesheet" href="css/standard_html.css" type="text/css" />
<link rel="stylesheet" href="css/sem.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://m-clark.github.io/sem/"><span style="font-size:125%; font-variant:small-caps; font-style:italic; color:#990024; font-family:Roboto">Structural Equation Modeling</span></a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#statistical"><i class="fa fa-check"></i>Statistical</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#programming"><i class="fa fa-check"></i>Programming</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#outline"><i class="fa fa-check"></i>Outline</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#graphical-models"><i class="fa fa-check"></i>Graphical Models</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#latent-variables"><i class="fa fa-check"></i>Latent Variables</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#sem"><i class="fa fa-check"></i>SEM</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#others"><i class="fa fa-check"></i>Others</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#programming-language-choice"><i class="fa fa-check"></i>Programming Language Choice</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#setup"><i class="fa fa-check"></i>Setup</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i>Introduction to R</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-started"><i class="fa fa-check"></i>Getting Started</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#packages"><i class="fa fa-check"></i>Packages</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#rstudio"><i class="fa fa-check"></i>RStudio</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#importing-data"><i class="fa fa-check"></i>Importing Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#key-things-to-know-about-r"><i class="fa fa-check"></i>Key things to know about R</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-is-a-programming-language-not-a-stats-package"><i class="fa fa-check"></i>R is a programming language, not a ‘stats package’</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#never-ask-if-r-can-do-what-you-want.-it-can."><i class="fa fa-check"></i>Never ask if R can do what you want. It can.</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#main-components-script-console-graphics-device"><i class="fa fa-check"></i>Main components: script, console, graphics device</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-is-easy-to-use-but-difficult-to-master."><i class="fa fa-check"></i>R is easy to use, but difficult to master.</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#object-oriented"><i class="fa fa-check"></i>Object-oriented</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#case-sensitive"><i class="fa fa-check"></i>Case sensitive</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#the-lavaan-package"><i class="fa fa-check"></i>The lavaan package</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#getting-help"><i class="fa fa-check"></i>Getting help</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#moving-forward"><i class="fa fa-check"></i>Moving forward</a><ul>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r.html"><a href="introduction-to-r.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html"><i class="fa fa-check"></i>Graphical Models</a><ul>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#directed-graphs"><i class="fa fa-check"></i>Directed Graphs</a><ul>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#standard-linear-model"><i class="fa fa-check"></i>Standard linear model</a></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#path-analysis"><i class="fa fa-check"></i>Path Analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#bayesian-networks"><i class="fa fa-check"></i>Bayesian Networks</a></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#undirected-graphs"><i class="fa fa-check"></i>Undirected Graphs</a><ul>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#network-analysis"><i class="fa fa-check"></i>Network analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="graphical-models-1.html"><a href="graphical-models-1.html#r-packages-used"><i class="fa fa-check"></i>R packages used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html"><i class="fa fa-check"></i>Latent Variables</a><ul>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#dimension-reductioncompression"><i class="fa fa-check"></i>Dimension Reduction/Compression</a><ul>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#principal-components-analysis"><i class="fa fa-check"></i>Principal Components Analysis</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#factor-analysis"><i class="fa fa-check"></i>Factor Analysis</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#other-techniques"><i class="fa fa-check"></i>Other Techniques</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#constructs-and-measurement-models"><i class="fa fa-check"></i>Constructs and Measurement Models</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#other-issues-in-factor-analysis"><i class="fa fa-check"></i>Other issues in Factor Analysis</a><ul>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#some-specific-factor-models-in-sem"><i class="fa fa-check"></i>Some specific factor models in SEM</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#scale-development"><i class="fa fa-check"></i>Scale development</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#factor-scores"><i class="fa fa-check"></i>Factor Scores</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#terminology"><i class="fa fa-check"></i>Terminology</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#some-other-uses-of-latent-variables"><i class="fa fa-check"></i>Some Other Uses of Latent Variables</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="latent-variables-1.html"><a href="latent-variables-1.html#r-packages-used-1"><i class="fa fa-check"></i>R packages used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html"><i class="fa fa-check"></i>Structural Equation Modeling</a><ul>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#measurement-model"><i class="fa fa-check"></i>Measurement Model</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#structural-model"><i class="fa fa-check"></i>Structural Model</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#the-process"><i class="fa fa-check"></i>The Process</a><ul>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#initial-considerations-of-complexity"><i class="fa fa-check"></i>Initial Considerations of Complexity</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#steps-to-take"><i class="fa fa-check"></i>Steps to Take</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#sem-example"><i class="fa fa-check"></i>SEM Example</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#issues-in-sem"><i class="fa fa-check"></i>Issues in SEM</a><ul>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#identification"><i class="fa fa-check"></i>Identification</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#fit"><i class="fa fa-check"></i>Fit</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#model-comparison"><i class="fa fa-check"></i>Model Comparison</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#prediction"><i class="fa fa-check"></i>Prediction</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#observed-covariates"><i class="fa fa-check"></i>Observed covariates</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#interactions"><i class="fa fa-check"></i>Interactions</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#estimation"><i class="fa fa-check"></i>Estimation</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#missing-data"><i class="fa fa-check"></i>Missing data</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#other-sem-approaches"><i class="fa fa-check"></i>Other SEM approaches</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#how-to-fool-yourself-with-sem"><i class="fa fa-check"></i>How to fool yourself with SEM</a><ul>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#sample-size"><i class="fa fa-check"></i>Sample size</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#poor-data"><i class="fa fa-check"></i>Poor data</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#naming-a-latent-variable-doesnt-mean-it-exists"><i class="fa fa-check"></i>Naming a latent variable doesn’t mean it exists</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#ignoring-diagnostics"><i class="fa fa-check"></i>Ignoring diagnostics</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#ignoring-performance"><i class="fa fa-check"></i>Ignoring performance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#terminology-1"><i class="fa fa-check"></i>Terminology</a></li>
<li class="chapter" data-level="" data-path="structural-equation-modeling.html"><a href="structural-equation-modeling.html#r-packages-used-2"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html"><i class="fa fa-check"></i>Latent Growth Curves</a><ul>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#random-effects"><i class="fa fa-check"></i>Random effects</a><ul>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#model-formality"><i class="fa fa-check"></i>Model formality</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#random-effects-in-sem"><i class="fa fa-check"></i>Random Effects in SEM</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#simulating-random-effects"><i class="fa fa-check"></i>Simulating Random Effects</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#running-a-growth-curve-model"><i class="fa fa-check"></i>Running a Growth Curve Model</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#thinking-more-generally-about-regression"><i class="fa fa-check"></i>Thinking more generally about regression</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#more-on-lgc"><i class="fa fa-check"></i>More on LGC</a><ul>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#lgc-are-non-standard-sem"><i class="fa fa-check"></i>LGC are non-standard SEM</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#residual-correlations"><i class="fa fa-check"></i>Residual correlations</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#nonlinear-time-effect"><i class="fa fa-check"></i>Nonlinear time effect</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#growth-mixture-models"><i class="fa fa-check"></i>Growth Mixture Models</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#other-covariates"><i class="fa fa-check"></i>Other covariates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#some-differences-between-mixed-models-and-growth-curves"><i class="fa fa-check"></i>Some Differences between Mixed Models and Growth Curves</a><ul>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#random-slopes"><i class="fa fa-check"></i>Random slopes</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#wide-vs.long"><i class="fa fa-check"></i>Wide vs. long</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#sample-size-1"><i class="fa fa-check"></i>Sample size</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#number-of-time-points"><i class="fa fa-check"></i>Number of time points</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#balance"><i class="fa fa-check"></i>Balance</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#numbering-the-time-points"><i class="fa fa-check"></i>Numbering the time points</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#other-stuff"><i class="fa fa-check"></i>Other stuff</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="latent-growth-curves.html"><a href="latent-growth-curves.html#r-packages-used-3"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html"><i class="fa fa-check"></i>Mixture Models</a><ul>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#a-motivating-example"><i class="fa fa-check"></i>A Motivating Example</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#create-clustered-data"><i class="fa fa-check"></i>Create Clustered Data</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#mixture-modeling-with-old-faithful"><i class="fa fa-check"></i>Mixture modeling with Old Faithful</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#sem-and-latent-categorical-variables"><i class="fa fa-check"></i>SEM and Latent Categorical Variables</a><ul>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#latent-categories-vs.multi-group-analysis"><i class="fa fa-check"></i>Latent Categories vs. Multi-group Analysis</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#latent-trajectories"><i class="fa fa-check"></i>Latent Trajectories</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#estimation-1"><i class="fa fa-check"></i>Estimation</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#terminology-in-sem"><i class="fa fa-check"></i>Terminology in SEM</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#summary-6"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="mixture-models.html"><a href="mixture-models.html#r-packages-used-4"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html"><i class="fa fa-check"></i>Item Response Theory</a><ul>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#standard-models"><i class="fa fa-check"></i>Standard Models</a><ul>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#one-parameter-model"><i class="fa fa-check"></i>One Parameter Model</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#two-parameter-model"><i class="fa fa-check"></i>Two Parameter Model</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#three-parameter-model"><i class="fa fa-check"></i>Three Parameter Model</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#four-parameter-model"><i class="fa fa-check"></i>Four Parameter Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#other-irt-models"><i class="fa fa-check"></i>Other IRT Models</a><ul>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#additional-covariates"><i class="fa fa-check"></i>Additional covariates</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#graded-response-model"><i class="fa fa-check"></i>Graded Response Model</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#multidimensional-irt"><i class="fa fa-check"></i>Multidimensional IRT</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#other-irt"><i class="fa fa-check"></i>Other IRT</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#summary-7"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#irt-terminology"><i class="fa fa-check"></i>IRT Terminology</a></li>
<li class="chapter" data-level="" data-path="item-response-theory.html"><a href="item-response-theory.html#r-packages-used-5"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="topic-models.html"><a href="topic-models.html"><i class="fa fa-check"></i>Topic Models</a><ul>
<li class="chapter" data-level="" data-path="topic-models.html"><a href="topic-models.html#latent-dirichlet-allocation"><i class="fa fa-check"></i>Latent Dirichlet Allocation</a></li>
<li class="chapter" data-level="" data-path="topic-models.html"><a href="topic-models.html#analysis"><i class="fa fa-check"></i>Analysis</a></li>
<li class="chapter" data-level="" data-path="topic-models.html"><a href="topic-models.html#summary-of-topic-models"><i class="fa fa-check"></i>Summary of Topic Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bayesian-nonparametric-models.html"><a href="bayesian-nonparametric-models.html"><i class="fa fa-check"></i>Bayesian Nonparametric Models</a><ul>
<li class="chapter" data-level="" data-path="bayesian-nonparametric-models.html"><a href="bayesian-nonparametric-models.html#chinese-restaurant-process"><i class="fa fa-check"></i>Chinese Restaurant Process</a></li>
<li class="chapter" data-level="" data-path="bayesian-nonparametric-models.html"><a href="bayesian-nonparametric-models.html#indian-buffet-process"><i class="fa fa-check"></i>Indian Buffet Process</a></li>
<li class="chapter" data-level="" data-path="bayesian-nonparametric-models.html"><a href="bayesian-nonparametric-models.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="bayesian-nonparametric-models.html"><a href="bayesian-nonparametric-models.html#r-packages-used-6"><i class="fa fa-check"></i>R packages used</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#data-set-descriptions"><i class="fa fa-check"></i>Data Set Descriptions</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#mcclelland"><i class="fa fa-check"></i>McClelland</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#national-longitudinal-survey-of-youth-1997-nlsy97"><i class="fa fa-check"></i>National Longitudinal Survey of Youth (1997, NLSY97)</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#wheaton-1977-data"><i class="fa fa-check"></i>Wheaton 1977 data</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#harman-5"><i class="fa fa-check"></i>Harman 5</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#big-five"><i class="fa fa-check"></i>Big Five</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#old-faithful"><i class="fa fa-check"></i>Old Faithful</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#harman-1974"><i class="fa fa-check"></i>Harman 1974</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#marsh-hocevar-1985"><i class="fa fa-check"></i>Marsh &amp; Hocevar 1985</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#abortion-attitudes"><i class="fa fa-check"></i>Abortion Attitudes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#terminology-in-sem-1"><i class="fa fa-check"></i>Terminology in SEM</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#problematic-andor-not-very-useful-terms"><i class="fa fa-check"></i>Problematic and/or not very useful terms</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#lavaan-output-explained"><i class="fa fa-check"></i>Lavaan Output Explained</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#code-examples"><i class="fa fa-check"></i>Code Examples</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#factor-analysis-via-maximum-likelihood"><i class="fa fa-check"></i>Factor Analysis via Maximum Likelihood</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#parallel-process-example"><i class="fa fa-check"></i>Parallel Process Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#causal-bias"><i class="fa fa-check"></i>Causal Bias</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#prediction-1"><i class="fa fa-check"></i>Prediction</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#chance"><i class="fa fa-check"></i>Chance</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#other"><i class="fa fa-check"></i>Other</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#some-references"><i class="fa fa-check"></i>Some references</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#software-revisited"><i class="fa fa-check"></i>Software Revisited</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#mplus"><i class="fa fa-check"></i>Mplus</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#r"><i class="fa fa-check"></i>R</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#stata"><i class="fa fa-check"></i>Stata</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#other-2"><i class="fa fa-check"></i>Other</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#resources"><i class="fa fa-check"></i>Resources</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#graphical-models-2"><i class="fa fa-check"></i>Graphical Models</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#potential-outcomes"><i class="fa fa-check"></i>Potential Outcomes</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#measurement-models-including-irt"><i class="fa fa-check"></i>Measurement Models (including IRT)</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#applied-sem"><i class="fa fa-check"></i>Applied SEM</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#nonparametric-models"><i class="fa fa-check"></i>Nonparametric models</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#lavaan"><i class="fa fa-check"></i>lavaan</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#other-sem-tools-in-r"><i class="fa fa-check"></i>Other SEM tools in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="other-3.html"><a href="other-3.html"><i class="fa fa-check"></i>Other</a></li>
<li><a href="section-1.html#section-1"></a></li>
<li class="divider"></li>
<li><a href="https://m-clark.github.io/"><img src="img/mc.png" style="width:50%; padding:0px 0; display:block; margin: 0 auto;" alt="MC logo"></a></li>
<li><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="width:50%; border-width:0; display:block; margin: 0 auto;" src="img/ccbysa_test.png" /></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><span style="font-size:150%; font-variant:small-caps; font-style:italic; ">Graphical and Latent Variable Modeling</span></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="graphical-models-1" class="section level1">
<h1>Graphical Models</h1>
<p>A graphical model can be seen as a mathematical or statistical construct connecting <em>nodes</em> (or vertices) via <em>edges</em> (or links). When pertaining to statistical models, the nodes might represent variables of interest in our data set, and edges specify the relationships among them. Visually they are depicted in the style of the following examples.</p>
<p><img src="img/graphicalModels.png" style="display:block; margin: 0 auto; width:50%"></p>
<p>Any statistical model you’ve conducted can be expressed as a graphical model. As an example, the first graph with nodes X, Y, and Z might represent a regression model in which X and Z predict Y. The emoticon graph shows an indirect effect, and the 123 graph might represent a correlation matrix.</p>
<p>A key idea of a graphical model is that of <span class="emph">conditional independence</span>, something one should keep in mind when constructing their models. The concept can be demonstrated with the following graph.</p>
<p><br> In this graph, X is <em>conditionally independent</em> of Z given Y- there is no correlation between X and Z once Y is accounted for<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. We will revisit this concept when discussing path analysis and latent variable models. Graphs can be <em>directed</em>, <em>undirected</em>, or <em>mixed</em>. Directed graphs have arrows, sometimes implying a causal flow (a difficult endeavor to demonstrate explicitly) or noting a time component. Undirected graphs merely denote relations among the nodes, while mixed graphs might contain both directional and symmetric relationships. Most of the models discussed in this document will be directed or mixed.</p>
<div id="directed-graphs" class="section level2">
<h2>Directed Graphs</h2>
<p>As noted previously, we can represent standard models as graphical models. In most of these cases we’d be dealing with directed or mixed graphs. Almost always we are specifically dealing with directed <em>acyclic</em> graphs, where there are no feedback loops.</p>
<div id="standard-linear-model" class="section level3">
<h3>Standard linear model</h3>
<p>Let’s start with the standard linear model (SLiM), i.e. a basic regression we might estimate via ordinary least squares (but not necessarily). In this setting, we want to examine the effect of each potential predictor (x* in the graph) on the target variable (y). The following shows what the graphical model might look like.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%;">
<div id="htmlwidget-60d076803d615f79945a" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-60d076803d615f79945a">{"x":{"diagram":"digraph DAG {\n\ngraph [rankdir = LR bgcolor=transparent]\n\nnode [shape = circle, fontcolor=gray25 color=gray80]\n\nnode [fontname=\"Helvetica\"]\nx1 [label=<x<sub>1<\/sub>>]; x2 [label=<x<sub>2<\/sub>>]; x3 [label=<x<sub>3<\/sub>>]; \n\nnode [fillcolor=gray90 style=filled]\ny;\n\nedge [color=gray50 style=filled]\nx1 -> y; x2 -> y; x3 -> y;\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<!-- <img src="img/regasgraph.png" style="display:block; margin: 0 auto; width:50%"> -->
<p>While we start simpler, we can use much of the same sort of thinking with more complex models later. In what follows, we’ll show that whether we use a standard R modeling approach (via the <span class="func">lm</span> function), or an SEM approach (via the <span class="func">sem</span> function in <span class="pack">lavaan</span>), the results are identical aside from the fact that sem is using maximum likelihood (so the variances will be slightly different). First, we’ll with the standard <span class="func">lm</span> approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mcclelland =<span class="st"> </span>haven<span class="op">::</span><span class="kw">read_dta</span>(<span class="st">&#39;data/path_analysis_data.dta&#39;</span>)
lmModel =<span class="st"> </span><span class="kw">lm</span>(math21 <span class="op">~</span><span class="st"> </span>male <span class="op">+</span><span class="st"> </span>math7 <span class="op">+</span><span class="st"> </span>read7 <span class="op">+</span><span class="st"> </span>momed, <span class="dt">data=</span>mcclelland)</code></pre></div>
<p>Now we can do the same model using the lavaan package, and while the input form will change a bit, and the output will be presented in a manner consistent with SEM, the estimated parameters are identical. Note that the square of the residual standard error in the <span class="func">lm</span> output is compared to the variance estimate in the lavaan output.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lavaan)
model =<span class="st"> &quot;</span>
<span class="st">  math21 ~ male + math7 + read7 + momed </span>
<span class="st">&quot;</span>
semModel =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>mcclelland, <span class="dt">meanstructure =</span> <span class="ot">TRUE</span>)

<span class="kw">summary</span>(lmModel)</code></pre></div>
<pre><code>
Call:
lm(formula = math21 ~ male + math7 + read7 + momed, data = mcclelland)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.9801 -1.2571  0.1376  1.4544  5.7471 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.84310    1.16418   4.160 4.08e-05 ***
male         1.20609    0.25831   4.669 4.44e-06 ***
math7        0.31306    0.04749   6.592 1.76e-10 ***
read7        0.08176    0.01638   4.991 9.81e-07 ***
momed       -0.01684    0.06651  -0.253      0.8    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.329 on 324 degrees of freedom
  (101 observations deleted due to missingness)
Multiple R-squared:  0.258, Adjusted R-squared:  0.2488 
F-statistic: 28.16 on 4 and 324 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(semModel, <span class="dt">rsq=</span>T)</code></pre></div>
<pre><code>lavaan (0.5-23.1097) converged normally after  21 iterations

                                                  Used       Total
  Number of observations                           329         430

  Estimator                                         ML
  Minimum Function Test Statistic                0.000
  Degrees of freedom                                 0
  Minimum Function Value               0.0000000000000

Parameter Estimates:

  Information                                 Expected
  Standard Errors                             Standard

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  math21 ~                                            
    male              1.206    0.256    4.705    0.000
    math7             0.313    0.047    6.642    0.000
    read7             0.082    0.016    5.030    0.000
    momed            -0.017    0.066   -0.255    0.799

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .math21            4.843    1.155    4.192    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .math21            5.341    0.416   12.826    0.000

R-Square:
                   Estimate
    math21            0.258</code></pre>
<p>As we will see in more detail later, SEM incorporates more complicated regression models, but at this point the parameters have the exact same understanding as our standard regression, because there is no difference between the two models except conceptually, in that SEM explicitly brings a causal aspect to bear on the interpretation. As we go along, we can see the structural equation models statistically as generalizations of those we are already well acquainted with, and so one can use that prior knowledge as a basis for understanding the newer ones.</p>
</div>
<div id="path-analysis" class="section level3">
<h3>Path Analysis</h3>
<p><span class="emph">Path Analysis</span>, and thus SEM, while new to some, is in fact a very, very old technique, statistically speaking<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. It can be seen as a generalization of the SLiM approach that can allow for indirect effects and multiple target variables. Path analysis also has a long history in the econometrics literature though under different names (e.g. instrumental variable regression, 2-stage least squares etc.), and through the computer science realm through the use of graphical models more generally. As such, there are many tools at your disposal for examining such models, and I’ll iterate that much of the SEM perspective on modeling comes largely from specific disciplines (especially psychology and education), while other approaches that are very common in other disciplines may be better for your situation.</p>
<div id="types-of-relationships" class="section level4">
<h4>Types of relationships</h4>
<p>The types of potential relationships examined by path analysis can be seen below.</p>
<p><img src="img/correlationComponents.png" style="display:block; margin: 0 auto; width:50%; height:50%;"></p>
<p>Most models deal only with <span class="emph">direct effects</span>. In this case there are no intervening variables we wish to consider. If such variables do exist, we are then dealing with what is often called a mediation model, and must interpret both <span class="emph">indirect</span> and (potentially) direct effects. When dealing with multiple outcomes, some may have predictors in common, such that the outcomes’ correlation can be explained by those <span class="emph">common causes</span> (this will come up in factor analysis later). Often there are <span class="emph">unanalyzed correlations</span>. As an example, every time you run a regression, the correlations among predictor variables are left ‘unanalyzed’.</p>
</div>
<div id="multiple-targets" class="section level4">
<h4>Multiple Targets</h4>
<p>While relatively seldom used, multivariate linear regression<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> is actually very straightforward in some programming environments such as R, and conducting models with multivariate outcomes does not require anything specific to SEM, but that is the realm we’ll stick with. Using the <a href="appendix.html#mcclelland">McClelland data</a>, let’s try it for ourselves. First, let’s look at the data to get a sense of things.</p>
<pre><code>                vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
attention4         1 430 17.93 3.05     18   18.03 2.97   9  25    16 -0.31    -0.17 0.15
math21             2 364 11.21 2.69     11   11.30 2.97   3  17    14 -0.26    -0.18 0.14
college            3 286  0.37 0.48      0    0.34 0.00   0   1     1  0.52    -1.74 0.03
vocab4             4 386 10.18 2.53     10   10.23 2.97   4  17    13 -0.18    -0.37 0.13
math7              5 397 10.73 2.76     11   10.69 2.97   4  19    15  0.13    -0.47 0.14
read7              6 390 31.57 8.05     30   30.87 8.90  18  61    43  0.79     0.41 0.41
read21             7 360 73.67 8.52     76   74.69 7.41  35  84    49 -1.60     3.88 0.45
adopted            8 430  0.49 0.50      0    0.48 0.00   0   1     1  0.06    -2.00 0.02
male               9 430  0.55 0.50      1    0.56 0.00   0   1     1 -0.19    -1.97 0.02
momed             10 419 14.83 2.03     15   14.77 1.48  10  21    11  0.11    -0.45 0.10
college_missing   11 430  0.33 0.47      0    0.29 0.00   0   1     1  0.70    -1.52 0.02</code></pre>
<p><div style="width:250px; margin:0 auto;">
<div id="htmlwidget-ef5ea76edfc173716a5d" style="width:350px;height:350px;" class="d3heatmap html-widget"></div>
<script type="application/json" data-for="htmlwidget-ef5ea76edfc173716a5d">{"x":{"rows":null,"cols":null,"matrix":{"data":["1","0.53","0.13","0.152","0.347","0.275","0.123","0.53","1","0.08","0.174","0.347","0.253","0.137","0.13","0.08","1","0.18","-0.059","-0.004","0.013","0.152","0.174","0.18","1","0.076","0.215","0.068","0.347","0.347","-0.059","0.076","1","0.386","0.187","0.275","0.253","-0.004","0.215","0.386","1","0.137","0.123","0.137","0.013","0.068","0.187","0.137","1"],"dim":[7,7],"rows":["read7","read21","momed","vocab4","math21","math7","attention4"],"cols":["read7","read21","momed","vocab4","math21","math7","attention4"]},"image":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAcAAAAHCAYAAADEUlfTAAAAyUlEQVQImQXBvU7CUACG4U+a2IbJ0dFdh96Bo/fg6OLQycF4DU7OegFyFyQOJi5lIJhAlJ+Yqqct8XjMgQLKeX0eJWnGWafPuGoYmQWdXkF3OGdSN7ROr851f32rdhzpb4skKY4ihYA0rho+3YYkzRgUHuo38Ba/DmhkFjy/ewaFJ0kzjNuQTx3Vzy+t3odVv/zWYfyl2cONDo4vlJdWxq2k7nDO44sFb8mnjrunGUma8Vou2ZnUDSGg/b1Ey/VWxq3U3o10dHKpfzN6g7PoJI9yAAAAAElFTkSuQmCC","theme":null,"options":{"xaxis_height":80,"yaxis_width":120,"xaxis_font_size":null,"yaxis_font_size":null,"brush_color":"#0000FF","show_grid":true,"anim_duration":500,"yclust_width":0,"xclust_height":0}},"evals":[],"jsHooks":[]}</script>
</div> <br> While these are only weakly correlated variables to begin with, one plausible model might try to predict math and reading at age 21 with measures taken at prior years.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> &quot;</span>
<span class="st">  read21 ~ attention4 + vocab4 + read7</span>
<span class="st">  math21 ~ attention4 + math7</span>
<span class="st">  read21 ~~ 0*math21</span>
<span class="st">&quot;</span>
mvregModel  =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>mcclelland, <span class="dt">missing=</span><span class="st">&#39;listwise&#39;</span>, <span class="dt">meanstructure =</span> T)
<span class="kw">coef</span>(mvregModel)</code></pre></div>
<pre><code>read21~attention4     read21~vocab4      read21~read7 math21~attention4      math21~math7    read21~~read21 
            0.128             0.377             0.537             0.091             0.347            51.837 
   math21~~math21          read21~1          math21~1 
            5.965            50.290             5.856 </code></pre>
<p>The last line of the model code clarifies that we are treating <strong>math21</strong> and <strong>read21</strong> as independent, and as such we are simply running two separate regressions simultaneously. Note also that the coefficients in the output with <code>~1</code> are the intercepts. We can compare this to standard R regression. A first step is taken to make the data equal to what was used in <span class="pack">lavaan</span>. For that we can use the <span class="pack">dplyr</span> package to select the necessary variables for the model, and then omit rows that have any missing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mcclellandComplete =<span class="st"> </span><span class="kw">select</span>(mcclelland, read21, math21, attention4, vocab4, read7, math7) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>na.omit
<span class="kw">lm</span>(read21 <span class="op">~</span><span class="st"> </span>attention4 <span class="op">+</span><span class="st"> </span>vocab4 <span class="op">+</span><span class="st"> </span>read7, <span class="dt">data=</span>mcclellandComplete)</code></pre></div>
<pre><code>
Call:
lm(formula = read21 ~ attention4 + vocab4 + read7, data = mcclellandComplete)

Coefficients:
(Intercept)   attention4       vocab4        read7  
    50.2904       0.1275       0.3770       0.5368  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(math21 <span class="op">~</span><span class="st"> </span>attention4 <span class="op">+</span><span class="st"> </span>math7, <span class="dt">data=</span>mcclellandComplete)</code></pre></div>
<pre><code>
Call:
lm(formula = math21 ~ attention4 + math7, data = mcclellandComplete)

Coefficients:
(Intercept)   attention4        math7  
    5.85633      0.09103      0.34732  </code></pre>
<p>Note that had the models for both outcomes been identical, we could have run both outcomes simultaneously using <span class="func">cbind</span> on the dependent variables<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. However, we can and probably should estimate the covariance of math and reading skill at age 21. Let’s rerun the path analysis removing that <span class="emph">constraint</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> &quot;</span>
<span class="st">  read21 ~ attention4 + vocab4 + read7</span>
<span class="st">  math21 ~ attention4 + math7</span>
<span class="st">&quot;</span>
mvregModel  =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>mcclelland, <span class="dt">missing=</span><span class="st">&#39;listwise&#39;</span>, <span class="dt">meanstructure =</span> T)
<span class="kw">coef</span>(mvregModel)</code></pre></div>
<pre><code>read21~attention4     read21~vocab4      read21~read7 math21~attention4      math21~math7    read21~~read21 
            0.140             0.388             0.494             0.092             0.330            51.958 
   math21~~math21    read21~~math21          read21~1          math21~1 
            5.968             3.202            51.316             6.020 </code></pre>
<p>We can see that the coefficients are now slightly different from the SLiM approach. The <code>read21~~math21</code> value represents the residual covariance between math and reading at age 21, i.e. after accounting for the other covariate relationships modeled, it tells us how correlated those skills are. Using <span class="func">summary</span> will show it to be statistically significant. I additionally ask for standardized output to see the correlation along with the covariance. It actually is not very strong even if it is statistically significant.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mvregModel, <span class="dt">standardized=</span>T)</code></pre></div>
<pre><code>lavaan (0.5-23.1097) converged normally after  38 iterations

                                                  Used       Total
  Number of observations                           304         430

  Estimator                                         ML
  Minimum Function Test Statistic               26.965
  Degrees of freedom                                 3
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Information                                 Expected
  Standard Errors                             Standard

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  read21 ~                                                              
    attention4        0.140    0.134    1.043    0.297    0.140    0.051
    vocab4            0.388    0.163    2.378    0.017    0.388    0.116
    read7             0.494    0.050    9.942    0.000    0.494    0.486
  math21 ~                                                              
    attention4        0.092    0.045    2.041    0.041    0.092    0.109
    math7             0.330    0.049    6.674    0.000    0.330    0.351

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
 .read21 ~~                                                             
   .math21            3.202    1.026    3.119    0.002    3.202    0.182

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read21           51.316    3.045   16.854    0.000   51.316    6.056
   .math21            6.020    0.951    6.327    0.000    6.020    2.285

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read21           51.958    4.214   12.329    0.000   51.958    0.724
   .math21            5.968    0.484   12.329    0.000    5.968    0.860</code></pre>
<p>Whether or not to take a multivariate/path-analytic approach vs. separate regressions is left to the researcher. It’s perhaps easier to explain univariate models in some circumstances. But as the above shows, it doesn’t take much to take into account correlated target variables.</p>
</div>
<div id="indirect-effects" class="section level4">
<h4>Indirect Effects</h4>
<p>So path analysis allows for multiple target variables, with the same or a mix of covariates for each target. What about <span class="emph">indirect effects</span>? Standard regression models examine direct effects only, and the regression coefficients reflect that direct effect. However, perhaps we think a particular covariate causes some change in another, which then causes some change in the target variable. This is especially true when some measures are collected at different time points. Note that in SEM, any variable in which an arrow is pointing to it in the graphical depiction is often called an <span class="emph">endogenous</span> variable, while those that only have arrows going out from them are <span class="emph">exogenous</span>. Exogenous variables may still have (unanalyzed) correlations among them. As we will see later, both observed and latent variables may be endogenous or exogenous.</p>
<p>Consider the following model.</p>
<p><img src="img/mediation.png" style="display:block; margin: 0 auto;" width=50%></p>
<p>Here we posit attention span and vocabulary at age 4 as indicative of what to expect for reading skill at age 7, and that is ultimately seen as a precursor to adult reading ability. In this model, attention span and vocabulary at 4 only have an indirect effect on adult reading ability through earlier reading skill. At least temporally it makes sense, so let’s code this up.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> &quot;</span>
<span class="st">  read21 ~ read7</span>
<span class="st">  read7 ~ attention4 + vocab4</span>
<span class="st">&quot;</span>

mediationModel  =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>mcclelland)
<span class="kw">summary</span>(mediationModel, <span class="dt">rsquare=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>lavaan (0.5-23.1097) converged normally after  21 iterations

                                                  Used       Total
  Number of observations                           305         430

  Estimator                                         ML
  Minimum Function Test Statistic                6.513
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.039

Parameter Estimates:

  Information                                 Expected
  Standard Errors                             Standard

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  read21 ~                                            
    read7             0.559    0.050   11.152    0.000
  read7 ~                                             
    attention4        0.270    0.151    1.791    0.073
    vocab4            0.488    0.186    2.629    0.009

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .read21           53.047    4.296   12.349    0.000
   .read7            66.779    5.408   12.349    0.000

R-Square:
                   Estimate
    read21            0.290
    read7             0.035</code></pre>
<p>What does this tell us? As before, we interpret the results as we would any other regression model, though conceptually there are two sets of models to consider (though they are estimated simultaneously<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>), one for reading at age 7 and one for reading at age 21. And indeed, one can think of path analysis as a series of linked regression models<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. Here we have positive relationships between both attention and vocabulary at age 4 and reading at age 7, and a positive effect of reading at age 7 on reading at age 21. Statistically speaking, our model appears to be viable, as there appear to be statistically significant estimates for each path.</p>
<p>However, look at the R<sup>2</sup> value for reading at age 7. We now see that there is little to no <em>practical</em> effect of the age 4 variables at all, as all we are accounting for is &lt; 4% of the variance, and all that we have really discovered is that prior reading ability affects later reading ability.</p>
<p>We can test the indirect effect itself by labeling the paths in the model code. In the following code, I label them based on the first letter of the variables involved (e.g. <code>vr</code> refers to the vocab to reading path), but note that these are arbitrary names. I also add the direct effects of the early age variable. While the indirect effect for vocab is statistically significant, as we already know there is not a strong correlation between these two variables, it’s is largely driven by the strong relationship between reading at age 7 and reading at age 21, which is probably not all that interesting. A comparison of AIC values, something we’ll talk more about later, would favor a model with only direct effects<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> &quot;</span>
<span class="st">  read21 ~ rr*read7 + attention4 + vocab4</span>
<span class="st">  read7 ~ ar*attention4 + vr*vocab4</span>
<span class="st">  </span>
<span class="st">  # Indirect effects</span>
<span class="st">  att4_read21 := ar*rr</span>
<span class="st">  vocab4_read21 := vr*rr</span>
<span class="st">&quot;</span>

mediationModel  =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>mcclelland)
<span class="kw">summary</span>(mediationModel, <span class="dt">rsquare=</span><span class="ot">TRUE</span>, <span class="dt">fit=</span>T, <span class="dt">std=</span>T)</code></pre></div>
<pre><code>lavaan (0.5-23.1097) converged normally after  28 iterations

                                                  Used       Total
  Number of observations                           305         430

  Estimator                                         ML
  Minimum Function Test Statistic                0.000
  Degrees of freedom                                 0

Model test baseline model:

  Minimum Function Test Statistic              121.544
  Degrees of freedom                                 5
  P-value                                        0.000

User model versus baseline model:

  Comparative Fit Index (CFI)                    1.000
  Tucker-Lewis Index (TLI)                       1.000

Loglikelihood and Information Criteria:

  Loglikelihood user model (H0)              -3602.058
  Loglikelihood unrestricted model (H1)      -3602.058

  Number of free parameters                          7
  Akaike (AIC)                                7218.115
  Bayesian (BIC)                              7244.157
  Sample-size adjusted Bayesian (BIC)         7221.957

Root Mean Square Error of Approximation:

  RMSEA                                          0.000
  90 Percent Confidence Interval          0.000  0.000
  P-value RMSEA &lt;= 0.05                             NA

Standardized Root Mean Square Residual:

  SRMR                                           0.000

Parameter Estimates:

  Information                                 Expected
  Standard Errors                             Standard

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
  read21 ~                                                              
    read7     (rr)    0.536    0.050   10.607    0.000    0.536    0.515
    attentin4         0.134    0.134    0.998    0.318    0.134    0.015
    vocab4            0.381    0.166    2.299    0.021    0.381    0.044
  read7 ~                                                               
    attentin4 (ar)    0.270    0.151    1.791    0.073    0.270    0.033
    vocab4    (vr)    0.488    0.186    2.629    0.009    0.488    0.059

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
   .read21           51.926    4.205   12.349    0.000   51.926    0.695
   .read7            66.779    5.408   12.349    0.000   66.779    0.965

R-Square:
                   Estimate
    read21            0.305
    read7             0.035

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
    att4_read21       0.145    0.082    1.766    0.077    0.145    0.017
    vocab4_read21     0.261    0.102    2.552    0.011    0.261    0.030</code></pre>
<p>In the original article, I did not find their description or diagrams of the models detailed enough to know precisely what the model was in the actual study<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, but here is at least one interpretation if you’d like to examine it further.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modReading =<span class="st"> &quot;</span>
<span class="st">  read21 ~ read7 + attention4 + vocab4 + male + adopted + momed</span>
<span class="st">  read7 ~ attention4 + vocab4</span>
<span class="st">&quot;</span>
reading  =<span class="st"> </span><span class="kw">sem</span>(modReading, <span class="dt">data=</span>mcclelland, <span class="dt">missing=</span><span class="st">&#39;fiml&#39;</span>, <span class="dt">mimic =</span> <span class="st">&#39;Mplus&#39;</span>, <span class="dt">std.ov=</span><span class="ot">TRUE</span>)
<span class="kw">summary</span>(reading, <span class="dt">rsquare=</span><span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="more-mediation" class="section level4">
<h4>More mediation</h4>
<p>Here I would like to demonstrate a powerful approach to mediation models using Imai’s <span class="pack">mediation</span> package. It is based on a theoretical framework that allows for notably complex models for mediator, outcome or both, including different types of variables for the mediator and outcome. While it is simple to conduct, the results suggest there are more things to think about when it comes to mediation.</p>
<p>To begin, we will run two separate models, one for the mediator and one for the outcome, using the mediate function to use them to estimate the mediation effect. In this case we’ll focus on the indirect effect of attention.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mediation)
mediator_model =<span class="st"> </span><span class="kw">lm</span>(read7 <span class="op">~</span><span class="st"> </span>attention4 <span class="op">+</span><span class="st"> </span>vocab4, <span class="dt">data=</span>mcclellandComplete)
outcome_model =<span class="st"> </span><span class="kw">lm</span>(read21 <span class="op">~</span><span class="st"> </span>read7 <span class="op">+</span><span class="st"> </span>attention4 <span class="op">+</span><span class="st"> </span>vocab4, <span class="dt">data=</span>mcclellandComplete)
results =<span class="st"> </span><span class="kw">mediate</span>(mediator_model, outcome_model, <span class="dt">treat=</span><span class="st">&quot;attention4&quot;</span>, <span class="dt">mediator =</span> <span class="st">&#39;read7&#39;</span>)
<span class="kw">summary</span>(results)</code></pre></div>
<pre><code>
Causal Mediation Analysis 

Quasi-Bayesian Confidence Intervals

               Estimate 95% CI Lower 95% CI Upper p-value  
ACME             0.1451      -0.0102         0.31   0.068 .
ADE              0.1281      -0.1213         0.39   0.348  
Total Effect     0.2732      -0.0193         0.58   0.060 .
Prop. Mediated   0.5232      -0.6462         2.72   0.092 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Sample Size Used: 304 


Simulations: 1000 </code></pre>
<p>The first thing to note is that there are multiple results to consider, we have the average causal mediated effect, the average direct effect, the total effect and the proportion mediated. What is an <span class="emph">average causal mediated effect</span>? First, think about a standard experimental design in which participants are assigned to control and treatment groups. Ideally, if we really wanted to know about true effects, we’d see the outcome when an individual was a control and when they were were in the treatment. The true <em>causal</em> effect for an individual would be the difference between their scores when in the control and when in the treatment. Thus there are two hypothetical situations of different conditions, or <span class="emph">counterfactuals</span>, of interest- what would be the <em>potential</em> outcome of a control case if they treated, and vice versa for those in the treated group<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>.</p>
<p>This <span class="emph">potential outcomes framework</span> is the essence of the <span class="func">mediate</span> function. In the presence of a mediator variable, we can start by defining the <span class="emph">average direct effect</span> (ζ) as follows, where <span class="math inline">\(Y_i\)</span> is the potential outcome for unit <span class="math inline">\(i\)</span> (e.g. a person), <span class="math inline">\(M_i\)</span> the potential outcome of the mediator, and <span class="math inline">\(T_i\)</span> the treatment status. From the mediate function help file<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>:</p>
<blockquote>
<p>The expected difference in the potential outcome when the treatment is changed but the mediator is held constant at the value that would realize if the treatment equals <span class="math inline">\(t\)</span></p>
</blockquote>
<p><span class="math display">\[ζ(t) = E[Y(t_1, M(t)) - Y(t_0, M(t))]\]</span></p>
<p>The <strong>ACME</strong> meanwhile is:</p>
<blockquote>
<p>The expected difference (δ) in the <em>potential outcome</em> when the mediator took the value that would realize under the treatment condition as opposed to the control condition, while the treatment status itself is held constant.</p>
</blockquote>
<p><span class="math display">\[δ(t) = E[Y(t, M(t_1)) - Y(t, M(t_0))]\]</span></p>
<blockquote>
<p>where <span class="math inline">\(t\)</span>, <span class="math inline">\(t_1\)</span>, <span class="math inline">\(t_0\)</span> are particular values of the treatment T such that <span class="math inline">\(t_1 \neq t_0\)</span>, M(t) is the potential mediator, and Y(t,m) is the potential outcome variable.</p>
</blockquote>
<p>Adding these two gives us the <span class="emph">total effect</span>. In the case of continuous variables, the values for ‘control’ and ‘treatment’ are fixed to specific values of interest, but by default represent a unit difference in the values of the variable. The results of the <span class="func">mediate</span> function are based on a simulation approach, and averaged over those simulations. You’ll note there is also a ‘proportion of effect mediated’. This is the size of the ACME to the the total effect. It too is averaged over the simulations (and thus is not simply the ACME/Total Effect reported values). It’s not clear to me how useful of a notion this is, and as noted by the boundaries, it’s actually a ratio as opposed to a true proportion (as calculated), such that under some simulations the value can be negative or greater than 1.</p>
<p>You may compare the result with the previous <span class="pack">lavaan</span> results. I’ve rerun it with bootstrap estimates (set <code>se='boot'</code>) to be more in keeping with the simulation approach of Imai<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>. You could also use the <span class="pack">blavaan</span> package to get true Bayesian estimates.</p>
<pre><code>          lhs op        rhs       label   est    se     z pvalue ci.lower ci.upper
1 att4_read21 :=      ar*rr att4_read21 0.145 0.082 1.772  0.076   -0.012    0.313
2      read21  ~ attention4             0.134 0.137 0.974  0.330   -0.107    0.425</code></pre>
<p>As expected, the results of <span class="pack">lavaan</span> and <span class="pack">mediation</span> packages largely agree with one another. However, the potential outcomes framework has the <em>product-of-paths</em> approach as a special case, and thus generalizes to different models and types of variables for the mediator and outcome.</p>
<div id="explicit-example" class="section level5">
<h5>Explicit Example</h5>
<p>While we have shown how to use the tool and compared the outputs, let’s make things more simple and explicit to be sure that we understand what’s going on. The following closely follows <a href="http://ftp.cs.ucla.edu/pub/stat_ser/r370.pdf">Pearl</a> (section 4.4)<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a>. Consider the following three variable setup with estimated parameters. We have a treatment variable that is dummy coded with 0 = ‘Control group’ and 1 = ‘Treatment group’, a continuous Mediator and Target variable.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-c21c9e549d72c0288bab" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-c21c9e549d72c0288bab">{"x":{"diagram":"digraph mediation {\ngraph [rankdir = LR bgcolor=transparent]\n\nnode [shape = rectangle, style=filled, fillcolor=\"#1f65b780\", color=gray80, width=.75]\n\nnode [fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"5%\"]\nTreatment; Mediator; Target;\n\nnode [shape=circle, width=.1, fixedsize=F, fontsize=8]\n# \"3\";\n\n\nedge [color=gray50, fontcolor=gray50]\n\n# subgraph{\n#   rankdir = TB;\n#   edge [dir=none]\n#   3 -> Mediator;\n#   rank = same; {Mediator; 3}; \n# }\n\nedge [label=\".3\"]\nTreatment -> Mediator;\n\nedge [label=\".2\"]\nMediator -> Target;\n\n\n\ngraph [rankdir = BT]\n  edge [minlen=5, label=\".5\"]\n  Treatment -> Target;\n\nsubgraph {\n   rank = same; {Treatment; Target}; \n}\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>In addition, we’ll consider just a single individual, whose observed values are ‘control’, i.e. 0, 3 for the mediator, and 2 for the target. We define the unique values <span class="math inline">\(\epsilon_*\)</span> that represent invariant characteristics that exist regardless of changes to interventions or counterfactual hypotheses and set them to the following:</p>
<p><span class="math inline">\(\epsilon_1 = 0\)</span></p>
<p><span class="math inline">\(\epsilon_2 = 3 - 0*.3 = 3\)</span></p>
<p><span class="math inline">\(\epsilon_3 = 2 - 0*.5 - 3*.2 = 1.4\)</span></p>
<p>If a person is in the control group, this setup suggests the predicted value for the Target would be 3*.2 + 1.4 = 2. Let’s now figure out what the value would be if this person was in the treatment. The Mediator value would now be 3 + 1*.3 = 3.3. This would in turn result in a predicted Target value as follows: 1.4 + 3.3*.2 + 1*.5 = 2.56. And we could take this approach for other situations. We could, for example, ask what the expected value be if the Treatment level is 0, but the Mediator was at whatever value it would have been, had the person received the treatment? The value is 3.3*.2 + 1.4 = 2.06, which if we subtract from when they are are fully in the control group gives us the mediated effect 2.06 - 2 = .06. In this linear model it is equivalent to indirect effect via the product-of-paths approach, .3*.2 = .06. But now with the estimate based on the target variable rather than coefficients, we don’t have to be restricted to linear models.</p>
<p>One thing to note about the above, despite not having a data set or statistical result, we engaged in attempting to understand causal relations among the variables under theoretical consideration. Even though we may use the tools of statistical analysis, the key things that separates SEM and common regression approaches is the <em>explicit</em> assumption of causal relations and the ability to test some causal claims<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a>.</p>
</div>
</div>
<div id="cavets-about-indirect-effects" class="section level4">
<h4>Cavets about indirect effects</h4>
<p>One should think very hard about positing an indirect effect, especially if there is no time component or obvious pseudo-causal path. If the effect isn’t immediately obvious, or you are dealing with cross-sectional data, then you should probably just examine the direct effects. Unlike other standard explorations one might do with models (e.g. look for nonlinear relationships), the underlying causal connection and associated assumptions are more explicit in this context. Many models I’ve seen in consulting struck me as arbitrary as far as which covariate served as the mediator, required a fairly convoluted explanation for its justification, or ignored other relevant variables because the reasoning would have to include a plethora of indirect effects if it were to be logically consistent. Furthermore, I can often ask one or two questions and will discover that researchers are actually interested in interactions (i.e. moderation), rather than indirect effects.</p>
<p>This document will not get into models that have <em>moderated mediation</em> and <em>mediated moderation</em>. In my experience these are often associated with models that are difficult to interpret at best, or are otherwise not grounded very strongly in substantive concerns<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a>. However, there are times, e.g. in experimental settings, which surprisingly few SEM are applied to for reasons unknown, where perhaps it would be very much appropriate. It is left to the reader to investigate those particular complexities when the time comes.</p>
<p>Too often investigators will merely throw in these indirect effects and simply report whether the effect is significant or not. If you hide their results and ask if the indirect effect is positive or negative, I suspect they might not even know. Even if not used, I think the perspective of the potential outcomes framework can help one think appropriately about the situation, and avoid unnecessary complications. If one wants to <em>explore</em> possible indirect paths, there are better <a href="graphical-models-1.html#bayesian-networks">approaches</a> which are still rooted within the structural causal model framework, which we’ll see shortly. In addition, a mediation model should always be compared to a simpler model with no mediation (e.g. via AIC).</p>
</div>
<div id="terminology-issues" class="section level4">
<h4>Terminology issues</h4>
<p>Some refer to models with indirect effects as <span class="emph">mediation</span> models<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a>, and that terminology appears commonly in the SEM (and esp. psychology) literature<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a>. Many applied researchers just starting out with SEM often confuse the term with <span class="emph">moderation</span>, which is called an <span class="emph">interaction</span> in every other statistical modeling context. As you begin your SEM journey, referring to <span class="emph">indirect effects</span> and <span class="emph">interactions</span> will likely keep you clear on what you’re modeling, and perhaps be clearer to those who may not be as familiar with SEM when you present your work.</p>
<p>In models with moderation, one will often see a specific variable denoted as the <em>moderator</em>. However, this is completely arbitrary in the vast majority of situations in which it is used. In a typical model that includes an interaction, it makes just as much sense to say that the <span class="math inline">\(\mathcal{A} \rightarrow \mathcal{Y}\)</span> relationship varies as a function of <span class="math inline">\(\mathcal{B}\)</span> as it does the <span class="math inline">\(\mathcal{B} \rightarrow \mathcal{Y}\)</span> relationship varies as a function of <span class="math inline">\(\mathcal{A}\)</span>. Some suggest using the term <em>moderation</em> when only when there is a potential causal relation, almost always temporal in nature, such that the moderator variable precedes the variable in question. In addition, the moderator and the variable moderated must be <em>uncorrelated</em><a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a>. While such restrictions would render almost every model I’ve ever seen that uses the term moderation as an ordinary interaction instead, the idea is that the moderator has a causal effect on the path between the variable in question and its target. This is why you see graphs like the one to the left below, which has no tie to any statistical model and generally confuses people more often than it illuminates (the <em>correct</em> graph is to the right). Again though, the actual model is statistically indistinguishable from a standard model including an interaction, so if you want to understand moderation, you simply need to understand what an interaction is.</p>
<!-- <img src="img/moderation.png" style="display:block; margin: 0 auto; width:75%"> -->
<div class="col2" text-align="center&gt;
&lt;img src=&quot;img/mod_problematic.png&quot; style=&quot;display:block; margin: 0 auto; float:left;&quot; width=75%&gt;
&lt;img src=&quot;img/mod_better.png&quot; style=&quot;display:block; margin: 0 auto; float:left;&quot; width=75%&gt;
&lt;/div&gt;

&lt;br&gt;
Like SEM relative to standard modeling techniques, so too is mediation and moderation to indirect effects and interactions. Statistically they are indistinguishable models. Theoretically however, there is an underlying causal framework, and in some cases specific causal claims can be tested (e.g. via simulation).

Recently I have also heard the phrase " spotlight="" analysis'="" to="" refer="" to="" a="" categorical="" by="" continuous="" variable="" interaction.="" please="" don't="" apply="" new="" terms="" to="" very="" old="" techniques="" in="" an="" attempt="" to="" make="" a="" model="" sound="" more="" interesting[^psychlit].="" the="" work="" should="" speak="" for="" itself="" and="" be="" as="" clearly="" expressed="" as="" possible.="" the="" gist="" is="" that="" if="" you="" want="" to="" talk="" about="" your="" relations="" using="" the="" terms="" 'mediation'="" and="" 'moderation'="" you'll="" want="" to="" have="" specific="" and="" explicit="" causal="" relations="" among="" the="" variables.="" if="" you="" are="" unsure,="" then="" the="" answer="" is="" clearly="" that="" you="" don't="" have="" that="" situation.="" however,="" you="" can="" still="" incorporate="" interactions="" as="" usual,="" and="" explore="" potential="" indirect="" effects="" by="" modeling="" the="" correlations,="" e.g.="" leaving="" the="" indirect="" path="" undirected.="" ####="" aside:="" instrumental="" variables="" path="" analysis="" of="" a="" different="" sort="" has="" a="" long="" history="" in="" econometrics.="" a="" very="" common="" approach="" one="" may="" see="" utilized="" is="" <span="">
<p><img src="img/mod_problematic.png" style="display:block; margin: 0 auto; float:left;" width=75%> <img src="img/mod_better.png" style="display:block; margin: 0 auto; float:left;" width=75%></p>
</div>
<p><br> Like SEM relative to standard modeling techniques, so too is mediation and moderation to indirect effects and interactions. Statistically they are indistinguishable models. Theoretically however, there is an underlying causal framework, and in some cases specific causal claims can be tested (e.g. via simulation).</p>
<p>Recently I have also heard the phrase ‘spotlight analysis’ to refer to a categorical by continuous variable interaction. Please don’t apply new terms to very old techniques in an attempt to make a model sound more interesting<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a>. The work should speak for itself and be as clearly expressed as possible.</p>
<p>The gist is that if you want to talk about your relations using the terms ‘mediation’ and ‘moderation’ you’ll want to have specific and explicit causal relations among the variables. If you are unsure, then the answer is clearly that you don’t have that situation. However, you can still incorporate interactions as usual, and explore potential indirect effects by modeling the correlations, e.g. leaving the indirect path undirected.</p>
</div>
<div id="aside-instrumental-variables" class="section level4">
<h4>Aside: Instrumental variables</h4>
<p>Path analysis of a different sort has a long history in econometrics. A very common approach one may see utilized is <span class="emph">instrumental variable</span> analysis. The model can be depicted graphically as follows:</p>
<p><img src="img/iv.png" style="display:block; margin: 0 auto;" width=50%></p>
<p>In the graph, <span class="math inline">\(\mathcal{Y}\)</span> is our target variable, <span class="math inline">\(\mathcal{X}\)</span> is the causal variable of interest, and <span class="math inline">\(\mathcal{Z}\)</span> the instrument. The instrumental variable must not be correlated with disturbance of the target variable (later depicted as <span class="math inline">\(\mathcal{U}\)</span>), and only has an indirect relation to <span class="math inline">\(\mathcal{Y}\)</span> through <span class="math inline">\(\mathcal{X}\)</span>. Neither target nor causal variable are allowed to effect the instrument directly or indirectly. In graph theory, this involves the notion of conditional independence we’ve mentioned before, where <span class="math inline">\(\mathcal{Z}\)</span> is conditionally independent of Y given X, or in other words, if we remove the <span class="math inline">\(\mathcal{X} \rightarrow \mathcal{Y}\)</span> path, <span class="math inline">\(\mathcal{Z}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span> are independent. Furthermore, <span class="math inline">\(\mathcal{Z}\)</span> is <em>not</em> conditionally independent of <span class="math inline">\(\mathcal{X}\)</span> with the removal of that path<a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>.</p>
<p>The motivating factor for such a model is that the simple <span class="math inline">\(\mathcal{X} \rightarrow \mathcal{Y}\)</span> path may not provide a means for determining a causal relationship, particularly if <span class="math inline">\(\mathcal{X}\)</span> is correlated with the error. As an example<a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a>, if we look at the relationship of earnings with education, the unspecified causes of earnings might include things, e.g. some general ‘ability’, that would be correlated with the potential causal variable of education attained. With error <span class="math inline">\(\mathcal{U}\)</span> we can show the following diagram that depicts the problem.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-49e7101770869742d42b" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-49e7101770869742d42b">{"x":{"diagram":"digraph iv {\ngraph [rankdir=LR  bgcolor=transparent]\n\nnode [shape = rectangle, style=filled, fillcolor=\"#1f65b780\", color=gray80, width=.25, height=.25,\n      fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"5%\"]\n\nX; Y;\n\nnode [shape = circle, alpha=.5, color=gray75 style=filled, fillcolor=gray90]\nU;\n\nedge [color=gray50, penwidth=.5, arrowsize=.5]\nX -> Y;\nU -> Y;\n\nsubgraph {\n   rank = same; U; Y;\n}\n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>When <span class="math inline">\(\mathcal{X}\)</span> is endogenous, that is not the case. Changes in <span class="math inline">\(\mathcal{X}\)</span> are associated with <span class="math inline">\(\mathcal{Y}\)</span>, but also <span class="math inline">\(\mathcal{U}\)</span>.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-4b045ad079240b3fc722" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-4b045ad079240b3fc722">{"x":{"diagram":"digraph iv {\ngraph [rankdir=BT bgcolor=transparent]\n\nnode [shape = rectangle, style=filled, fillcolor=\"#1f65b780\", color=gray80, width=.25, height=.25,\n      fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"5%\"]\n\nX; Y;\n\nnode [shape = circle, alpha=.5, color=gray75 style=filled, fillcolor=gray90]\nU;\n\nedge [color=gray50, penwidth=.5, arrowsize=.5]\nX -> Y;\nU -> {X Y};\n\nsubgraph {\n   rank = same; X; Y;\n}\n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>There are now multiple effects of <span class="math inline">\(\mathcal{X}\)</span> on <span class="math inline">\(\mathcal{Y}\)</span>, both directly from <span class="math inline">\(\mathcal{X}\)</span> and indirectly from <span class="math inline">\(\mathcal{U}\)</span>. We can measure the association between <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span>, but not the causal relationship.</p>
<p>An attempt can be made to remedy the problem by using an instrument, leading the following graph.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-b192d009c2f391cf9549" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-b192d009c2f391cf9549">{"x":{"diagram":"digraph iv {\ngraph [rankdir=BT bgcolor=transparent]\n\nnode [shape = rectangle, style=filled, fillcolor=\"#1f65b780\", color=gray80, width=.25, height=.25,\n      fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"5%\"]\n\nX; Y; Z;\n\nnode [shape = circle, alpha=.5, color=gray75 style=filled, fillcolor=gray90]\nU;\n\nedge [color=gray50, penwidth=.5, arrowsize=.5]\nX -> Y;\nU -> {X Y};\nZ -> X;\n\nsubgraph {\n   rank = same; {X Y Z};\n}\n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>The instrument <span class="math inline">\(\mathcal{Z}\)</span> affects <span class="math inline">\(\mathcal{X}\)</span> and thus is correlated with <span class="math inline">\(\mathcal{Y}\)</span> indirectly. However, unlike <span class="math inline">\(\mathcal{X}\)</span>, it is uncorrelated with <span class="math inline">\(\mathcal{U}\)</span>. This assumption excludes <span class="math inline">\(\mathcal{Z}\)</span> from having a direct effect in the model for <span class="math inline">\(\mathcal{Y}\)</span>. If instead <span class="math inline">\(\mathcal{Y}\)</span> depended on both <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{Z}\)</span> but only <span class="math inline">\(\mathcal{X}\)</span> has a direct path to <span class="math inline">\(\mathcal{Y}\)</span>, then <span class="math inline">\(\mathcal{Z}\)</span> is basically absorbed into the error so would be correlated with it. With the direct path from <span class="math inline">\(\mathcal{Z}\)</span> to <span class="math inline">\(\mathcal{Y}\)</span> not allowed, we are left with only its influence on <span class="math inline">\(\mathcal{X}\)</span> .</p>
<p>Such models were commonly fit with a technique known two-stage least squares, which is demonstrated here. I use a subset of the <span class="objclass">CigarettesSW</span> data set and <span class="func">ivreg</span> function from the <span class="pack">AER</span> package for comparison. The data concerns cigarette consumption for the 48 continental US States from 1985–1995, though only the last year is used for our purposes. Here we examine the effect on packs per capita (packs) of price (<code>rprice</code>), using state level income (<code>rincome</code>) as the instrumental variable. See the help file for the <span class="objclass">CigarettesSW</span> for more on this data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(Cigarettes)  <span class="co"># raw, logged values actually used in models</span></code></pre></div>
<pre><code>  state   rprice  rincome     tdiff      tax   cpi     packs year
1    AL 103.9182 12.91535 0.9216975 40.50000 1.524 101.08543 1995
2    AR 115.1854 12.16907 5.4850193 55.50000 1.524 111.04297 1995
3    AZ 130.3199 13.53964 6.2057067 65.33333 1.524  71.95417 1995
4    CA 138.1264 16.07359 9.0363074 61.00000 1.524  56.85931 1995
5    CO 109.8097 16.31556 0.0000000 44.00000 1.524  82.58292 1995
6    CT 143.2287 20.96236 8.1072834 74.00000 1.524  79.47219 1995</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># explicit 2sls</span>
mod0 =<span class="st"> </span><span class="kw">lm</span>(rprice <span class="op">~</span><span class="st">  </span>rincome , <span class="dt">data =</span> Cigarettes)
<span class="kw">lm</span>(packs <span class="op">~</span><span class="st"> </span><span class="kw">fitted</span>(mod0), <span class="dt">data =</span> Cigarettes) </code></pre></div>
<pre><code>
Call:
lm(formula = packs ~ fitted(mod0), data = Cigarettes)

Coefficients:
 (Intercept)  fitted(mod0)  
       7.919        -0.707  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## using AER package
ivmod =<span class="st"> </span>AER<span class="op">::</span><span class="kw">ivreg</span>(packs <span class="op">~</span><span class="st"> </span>rprice <span class="op">|</span><span class="st"> </span>rincome,  <span class="dt">data =</span> Cigarettes)
<span class="kw">summary</span>(ivmod)</code></pre></div>
<pre><code>
Call:
AER::ivreg(formula = packs ~ rprice | rincome, data = Cigarettes)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.64455 -0.08910  0.01721  0.11352  0.45742 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   7.9191     2.0819   3.804 0.000419 ***
rprice       -0.7070     0.4354  -1.624 0.111265    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.2006 on 46 degrees of freedom
Multiple R-Squared: 0.3351, Adjusted R-squared: 0.3207 
Wald test: 2.637 on 1 and 46 DF,  p-value: 0.1113 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ymod =<span class="st"> </span><span class="kw">lm</span>(packs <span class="op">~</span><span class="st"> </span>rincome, <span class="dt">data =</span> Cigarettes)</code></pre></div>
<p>We can see that these both produce the same results, though actually doing the piecemeal regression would lead to problematic standard errors. However, by using the fitted values from the regression of <span class="math inline">\(\mathcal{X}\)</span> on <span class="math inline">\(\mathcal{Z}\)</span>, we are now able to essentially get the effect of <span class="math inline">\(\mathcal{X}\)</span> untainted by <span class="math inline">\(\mathcal{U}\)</span>. To see more clearly where the effect comes from, the coefficient of regressing <code>packs</code> on <code>income</code> is -0.347, and dividing that by the coefficient of <code>price</code> on <code>income</code>, 0.492, will provide the ultimate effect of price on the pack of cigarettes that we see above.</p>
<p>We can run the path model in <span class="pack">lavaan</span> as well. Note the slight difference between what we’d normally code up for a path model. In order to get the same results as instrumental variable regression, we have to explicitly add an estimate of the packs disturbance with price.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod =<span class="st"> &#39;</span>
<span class="st">  packs ~ rprice</span>
<span class="st">  rprice ~ rincome</span>
<span class="st">  packs ~~ rprice</span>
<span class="st">&#39;</span>

modiv =<span class="st"> </span><span class="kw">sem</span>(mod, <span class="dt">data=</span>Ciglog, <span class="dt">meanstructure =</span> T, <span class="dt">se =</span> <span class="st">&#39;robust&#39;</span>)
<span class="kw">summary</span>(modiv)</code></pre></div>
<pre><code>lavaan (0.5-23.1097) converged normally after  49 iterations

  Number of observations                            48

  Estimator                                         ML
  Minimum Function Test Statistic                0.000
  Degrees of freedom                                 0
  Minimum Function Value               0.0000000000000

Parameter Estimates:

  Information                                 Expected
  Standard Errors                           Robust.sem

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  packs ~                                             
    rprice           -0.707    0.432   -1.638    0.101
  rprice ~                                            
    rincome           0.492    0.123    3.991    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .packs ~~                                            
   .rprice           -0.008    0.006   -1.277    0.202

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .packs             7.919    2.075    3.816    0.000
   .rprice            3.464    0.324   10.684    0.000

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .packs             0.039    0.015    2.515    0.012
   .rprice            0.012    0.002    4.926    0.000</code></pre>
<p>While instrumental variable regression is common, this is perhaps not a typical path model seen in SEM. With SEM, a model comparison approach might be taken to compare models of competing complexity. One issue not discussed is where instruments come from. Generally data is not collected with acquiring them in mind, so it might be very difficult to use such an analysis. Furthermore, the structured causal framework that includes SEM would generally be a more flexible approach.</p>
<div id="heckman-selection-model" class="section level5">
<h5>Heckman Selection Model</h5>
<p>A different kind of instrumental variable model comes into play with sample selection models. Very common in econometrics or those exposed to it, and practically nowhere else, in this situation, our dependent variable is censored in some fashion, such that we only observe some the population. The classic, and evidently only, textbook example you’ll find on this regards the wages of working women. Here is the description from the Stata manual.</p>
<blockquote>
<p>In one classic example, the first equation describes the wages of women. Women choose whether to work, and thus, from our point of view as researchers, whether we observe their wages in our data. If women made this decision randomly, we could ignore that not all wages are observed and use ordinary regression to fit a wage model. Such an assumption of random participation, however, is unlikely to be true; women who would have low wages may be unlikely to choose to work, and thus the sample of observed wages is biased upward. In the jargon of economics, women choose not to work when their personal reservation wage is greater than the wage offered by employers. Thus women who choose not to work might have even higher offer wages than those who do work—they may have high offer wages, but they have even higher reservation wages. We could tell a story that competency is related to wages, but competency is rewarded more at home than in the labor force.</p>
</blockquote>
<p>So the primary problem here again is bias. Now you may say- but I’m not interested in the generalizing to all women<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>, or, if I were really worried about exact inference there are a whole host of other things being ignored, but the economists will have none of it<a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a>. Conceptually, the model is as follows:</p>
<p><span class="math display">\[ y = X\beta + \epsilon\]</span> <span class="math display">\[\mathrm{observed} = Z\gamma + \nu\]</span> <span class="math display">\[\begin{pmatrix}
\epsilon \\ \nu
\end{pmatrix}
\sim N\begin{bmatrix}
\begin{pmatrix}
0 \\ 0
\end{pmatrix},
\begin{pmatrix}
\sigma &amp; \rho\\
\rho &amp; 1
\end{pmatrix}\end{bmatrix}\]</span></p>
<p>There are actually two models to consider- one that we care about, and one regarding whether we observe the target variable <span class="math inline">\(y\)</span> or not. As before, we have the correlated errors issue, and, as with instrumental variable regression, we can take a two step approach here, albeit a bit differently. In the one model, we will predict whether the data is observed or not using a probit model. Then we’ll use a variable based on the fits from that model in the next step. Note these are not the fitted values, but the <span class="emph">inverse Mills ratio</span>, or in survival model lingo, the nonselection hazard, based on them. I show results using the <span class="pack">sampleSelection</span> package, and how to duplicate the process with standard R model functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wages =<span class="st"> </span>haven<span class="op">::</span><span class="kw">read_dta</span>(<span class="st">&#39;data/heckman_women.dta&#39;</span>) 
<span class="kw">library</span>(sampleSelection)
wages<span class="op">$</span>select_outcome =<span class="st"> </span><span class="kw">factor</span>(<span class="op">!</span><span class="kw">is.na</span>(wages<span class="op">$</span>wage), <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&#39;not&#39;</span>, <span class="st">&#39;observed&#39;</span>))

selection_model =<span class="st"> </span><span class="kw">selection</span>(select_outcome <span class="op">~</span><span class="st"> </span>married <span class="op">+</span><span class="st"> </span>children <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>age, 
                            wage <span class="op">~</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>age,
                            <span class="dt">data=</span>wages, <span class="dt">method=</span><span class="st">&#39;2step&#39;</span>)
<span class="kw">summary</span>(selection_model)</code></pre></div>
<pre><code>--------------------------------------------
Tobit 2 model (sample selection model)
2-step Heckman / heckit estimation
2000 observations (657 censored and 1343 observed)
11 free parameters (df = 1990)
Probit selection equation:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -2.467365   0.192563 -12.813  &lt; 2e-16 ***
married      0.430857   0.074208   5.806 7.43e-09 ***
children     0.447325   0.028742  15.564  &lt; 2e-16 ***
education    0.058365   0.010974   5.318 1.16e-07 ***
age          0.034721   0.004229   8.210 3.94e-16 ***
Outcome equation:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.73404    1.24833   0.588    0.557    
education    0.98253    0.05388  18.235   &lt;2e-16 ***
age          0.21187    0.02205   9.608   &lt;2e-16 ***
Multiple R-Squared:0.2793,  Adjusted R-Squared:0.2777
   Error terms:
              Estimate Std. Error t value Pr(&gt;|t|)    
invMillsRatio   4.0016     0.6065   6.597 5.35e-11 ***
sigma           5.9474         NA      NA       NA    
rho             0.6728         NA      NA       NA    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
--------------------------------------------</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># probit model</span>
probit =<span class="st"> </span><span class="kw">glm</span>(select_outcome <span class="op">~</span><span class="st"> </span>married <span class="op">+</span><span class="st"> </span>children <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>age, 
             <span class="dt">data=</span>wages, 
             <span class="dt">family=</span><span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&#39;probit&#39;</span>))

<span class="co"># setup for wage model</span>
probit_lp =<span class="st"> </span><span class="kw">predict</span>(probit)
mills0 =<span class="st"> </span><span class="kw">dnorm</span>(probit_lp)<span class="op">/</span><span class="kw">pnorm</span>(probit_lp)
imr =<span class="st"> </span>mills0[wages<span class="op">$</span>select_outcome<span class="op">==</span><span class="st">&#39;observed&#39;</span>]

lm_select =<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>imr, <span class="dt">data=</span><span class="kw">filter</span>(wages, select_outcome<span class="op">==</span><span class="st">&#39;observed&#39;</span>))
<span class="kw">summary</span>(probit)</code></pre></div>
<pre><code>
Call:
glm(formula = select_outcome ~ married + children + education + 
    age, family = binomial(link = &quot;probit&quot;), data = wages)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7594  -0.9414   0.4552   0.8459   2.0427  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -2.467365   0.192291 -12.831  &lt; 2e-16 ***
married      0.430857   0.074310   5.798 6.71e-09 ***
children     0.447325   0.028642  15.618  &lt; 2e-16 ***
education    0.058365   0.011018   5.297 1.18e-07 ***
age          0.034721   0.004232   8.204 2.33e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2532.4  on 1999  degrees of freedom
Residual deviance: 2054.1  on 1995  degrees of freedom
AIC: 2064.1

Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm_select)</code></pre></div>
<pre><code>
Call:
lm(formula = wage ~ education + age + imr, data = filter(wages, 
    select_outcome == &quot;observed&quot;))

Residuals:
     Min       1Q   Median       3Q      Max 
-15.4167  -3.5143  -0.1737   3.5506  20.3762 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.73404    1.16621   0.629    0.529    
education    0.98253    0.05050  19.457  &lt; 2e-16 ***
age          0.21187    0.02066  10.253  &lt; 2e-16 ***
imr          4.00162    0.57710   6.934 6.35e-12 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.359 on 1339 degrees of freedom
Multiple R-squared:  0.2793,    Adjusted R-squared:  0.2777 
F-statistic:   173 on 3 and 1339 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Dividing the coefficient for <code>imr</code> by <span class="math inline">\(\sigma\)</span> will give you a rough estimate of <span class="math inline">\(\rho\)</span>, but the <span class="math inline">\(\sigma\)</span> from the package results is the <span class="func">lm</span> <span class="objclass">sigma</span> plus an extra component, so the rough estimate of <span class="math inline">\(\rho\)</span> from just the <span class="func">lm</span> results will be a bit larger.</p>
<p>Unfortunately there isn’t a real good way to formulate this in SEM. Conceptually it’s still an instrumental variable type of model, but the complete separation of the data, where part of the model only exists for one category means that standard approaches won’t estimate it. Probably a good thing in the end. You could however estimate the IMR, and do the second step only using robust standard errors. It still won’t be exactly the same as the <span class="pack">sampleSelection</span> result, but close. If you’d like to see more detail, check <a href="https://github.com/m-clark/Miscellaneous-R-Code/blob/master/ModelFitting/heckman_selection.R">this out</a>.</p>
</div>
</div>
<div id="aside-nonrecursive-models" class="section level4">
<h4>Aside: Nonrecursive Models</h4>
<p>Recursive models have all unidirectional causal effects and disturbances are not correlated. A model is considered nonrecursive if there is a reciprocal relationship, feedback loop, or correlated disturbance in the model<a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a>. Nonrecursive models are potentially problematic when there is not enough information to estimate the model (unidentified model), which is a common concern with them.</p>
<p>A classic example of a nonrecursive relationship is marital satisfaction: the more satisfied one partner is, the more satisfied the other, and vice versa (at least that’s the theory). This can be represented by a simple model (below).</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-de9247fed478d612dc36" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-de9247fed478d612dc36">{"x":{"diagram":"digraph iv {\n  graph [rankdir=LR bgcolor=transparent]\n  \n  node [shape = rectangle, style=filled, fillcolor=\"#ff5500\", color=gray80, \n        fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"10%\"]\n  \n  H [label=\"Hus.\\n Satis\"]; \n  W [label=\"Wife\\n Satis\"];\n  \n  edge [shape = circle, alpha=.5 color=gray50 style=filled penwidth=.75 arrowsize=.75 minlen=4]\n  H -> W;\n  W -> H;\n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>Such models are notoriously difficult to specify in terms of <em>identification</em>, which we will talk more about later. For now, we can simply say the above model would not even be estimated as there are more parameters to estimate (two paths, two variances) than there is information in the data (two variances and one covariance).</p>
<p>To make this model identified, we use <span class="emph">instrumental variables</span> as we did before. In this scenario, instrumental variables directly influence one of the variables in a recursive relationship, but not the other. For example, a wife’s education can influence her satisfaction directly and a husband’s education can influence his satisfaction directly, but a husband’s education cannot directly impact a wife’s satisfaction and vice versa (at least for this demonstration). These instrumental variables can indirectly impact a spouses’ satisfaction. In the following model family income is also included. The dashed line represents an unanalyzed correlation.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; font-size:50%">
<div id="htmlwidget-a8f183ecf590bbce059c" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-a8f183ecf590bbce059c">{"x":{"diagram":"digraph iv {\n  graph [rankdir=LR splines=true bgcolor=transparent]\n  \n  node [shape = rectangle, style=filled, fillcolor=\"#ff5500\", color=gray80, \n        fontcolor=white, fontname=Roboto, fixedsize=true, fontsize=\"10%\"]\n  subgraph {\n    rank = same;\n    H [label=\"Hus.\\n Satis\"]; \n    Inc [label=\"Family\\n Income\"]; \n    W [label=\"Wife\\n Satis\"];\n  }\n  subgraph {\n    rank = same;\n    Hed [label=\"Hus.\\n Edu\"]; \n    Wed [label=\"Wife\\n Edu\"];\n  }\n\n  subgraph {  \n    #rank = same;\n    stupid [style=invisible  width=0 height=0 shape=none];\n    #Inc;\n  }\n  \n  edge [shape = circle, alpha=.5 color=gray50 style=filled penwidth=.75 arrowsize=.75 minlen=2]\n  Hed -> Inc [minlen=2];\n  Wed -> Inc [minlen=2];\n  Hed -> Wed [style=dashed dir=both headport=\"w\" tailport=\"w\"];\n  #Inc -> W;\n  W -> Inc [dir=back];\n  Inc -> H [];\n  #H -> W [dir=both];\n  stupid -> Inc [style=invisible arrowhead=none minlen=1 ];\n  H -> stupid [style=curved dir=back tailport=\"e\" minlen=0];\n  W -> stupid [style=curved dir=back tailport=\"e\" minlen=0];\n  #W -> H [style=curved dir=both headport=\"ne\" tailport=\"se\"  minlen=1];  # unfucking believable\n  #H -> W [style=curved dir=both];\n  \n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<p>Many instances of nonrecursive models might better be represented by a correlation. One must have a very strong theoretical motivation for such models, which is probably why they aren’t seen as often in the SEM literature, though they are actually quite common in some areas such as economics, where theory is assumed to be stronger (by economists).</p>
</div>
<div id="aside-tracing-rule" class="section level4">
<h4>Aside: Tracing rule</h4>
<p>In a recursive model, <span class="emph">implied correlations</span> between two variables, X1 and X2, can be found using <span class="emph">tracing rules</span>. Implied correlations between variables in a model are equal to the sum of the product of all standardized coefficients for the paths between them. Valid tracings are all routes between X1 and X2 that a) do not enter the same variable twice, and b) do not enter a variable through an arrowhead and leave through an arrowhead. The following examples assume the variables have been standardized (variance values equal to 1), if standardization has not occurred the variance of variables passed through should be included in the product of tracings.</p>
<p>Consider the following variables, A, B, and C (in a data frame called <span class="objclass">abc</span>) with a model seen in the below diagram. We are interested in identifying the implied correlation between x and z by decomposing the relationship into its different components and using tracing rules.</p>
<!-- something about semplot is screwy too, so don't cache it either -->
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(abc)</code></pre></div>
<pre><code>    A   B   C
A 1.0 0.2 0.3
B 0.2 1.0 0.7
C 0.3 0.7 1.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model =<span class="st"> &quot;</span>
<span class="st">  C ~ B + A</span>
<span class="st">  B ~ A</span>
<span class="st">&quot;</span>

pathMod =<span class="st"> </span><span class="kw">sem</span>(model, <span class="dt">data=</span>abc)
<span class="kw">coef</span>(pathMod)</code></pre></div>
<pre><code>  C~B   C~A   B~A  C~~C  B~~B 
0.667 0.167 0.200 0.478 0.950 </code></pre>
<p><img src="sem_files/figure-html/traceCoefs-1.svg" width="672" style="display: block; margin: auto;" /></p>
<p>To reproduce the correlation between A and C (sometimes referred to as a ‘total effect’):</p>
<ul>
<li>Corr = ac + ab * ac</li>
<li>Corr = 0.667 + 0.033</li>
<li>Corr = 0.7</li>
</ul>
<p>In SEM models, it’s important to consider how well our model-implied correlations correspond to the actual observed correlations. For <em>over-identified</em> models, the correlations will not be reproduced exactly, and thus can serve as a measure of how well our model fits the data. We’ll discuss this more later. In addition, the tracing of paths is important in understanding the <span class="emph">structural causal models</span> approach of Judea Pearl, of which SEM and the potential outcomes framework are part of.</p>
</div>
</div>
</div>
<div id="bayesian-networks" class="section level2">
<h2>Bayesian Networks</h2>
<p>In many cases of path analysis, the path model is not strongly supported by prior research or intuition, and in other cases, people are willing to use <span class="emph">modification indices</span> after the fact to change the paths in their model. This is unfortunate, as their model is generally <em>overfit</em> to begin with, and more so if altered in such an ad hoc fashion.</p>
<p>A more exploratory approach to graphical models is available however. <span class="emph">Bayesian Networks</span>, an approach within Pearl’s structural causal model framework and which led to its development, are an alternative to graphical modeling of the sort we’ve been doing. Though they can be used to produce exactly the same results that we obtain with path analysis via maximum likelihood estimation, they can also be used for constrained or wholly exploratory endeavors as well, potentially with regularization in place to help reduce overfitting.</p>
<p>As an example, I use the McClelland data to explore potential paths via the <span class="pack">bnlearn</span> package. I make the constraints that variables later in time do not effect variables earlier in time<a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a>, no variables are directed toward background characteristics like sex, and at least for these purposes I keep math and reading at a particular time from having paths to each other. I show some of the so-called <em>blacklist</em> of constraints here. Note that we can also require certain paths be in the model via a <em>whitelist</em>.</p>
<pre><code>    from         to
1 read21      read7
2 read21      math7
3 read21 attention4
4 read21     vocab4
5 read21    adopted
6 read21       male</code></pre>
<p>Now we can run the model. In this case we’ll use the <em>Grow-Shrink</em> algorithm, which is one of the simpler available in the package, though others came to the same conclusion<a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bnlearn)
model =<span class="st"> </span><span class="kw">gs</span>(mcclellandNoCollege, <span class="dt">blacklist =</span> blacklist, <span class="dt">test=</span><span class="st">&#39;mi-g-sh&#39;</span>)  </code></pre></div>
<div id="htmlwidget-b250ea7ddfd30f0be2e0" style="width:75%;height:480px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-b250ea7ddfd30f0be2e0">{"x":{"nodes":{"id":["vocab4","math7","read21","math21","read7","adopted","male","momed"],"label":["vocab4","math7","read21","math21","read7","adopted","male","momed"],"value":[100,100,100,100,100,100,100,100]},"edges":{"from":["vocab4","vocab4","math7","read7","read7","adopted","adopted","male","momed"],"to":["math7","read21","math21","math21","read21","math21","read21","math21","vocab4"]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"circle","color":{"background":"#ff5500","highlight":{"background":"salmon"}},"font":{"size":12,"color":"#fff"},"shadow":{"enabled":true,"color":"rgba(0,0,0,0.25)"},"scaling":{"label":{"enabled":true,"min":10,"max":12},"max":5}},"manipulation":{"enabled":false},"edges":{"arrows":"to","color":"#00aaff","smooth":{"enabled":true,"forceDirection":"horizontal"}},"layout":{"randomSeed":123}},"groups":null,"width":"75%","height":null,"idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>The plot of the model results shows that attention span at age 4 has no useful relationship to the other variables, something we’d already suspected based on previous models, and even could guess at the outset given its low correlations. As it has no connections, I’ve dropped it from the visualization. Furthermore, the remaining paths make conceptual sense. The parameters, fitted values, and residuals can be extracted with the <span class="func">bn.fit</span> function, and other diagnostic plots, cross-validation and prediction on new data are also available.</p>
<p>We won’t get into the details of these models except to say that one should have them in their tool box. And if one really is in a more exploratory situation, they would typically come with methods far better suited for the situation than the SEM tools, none of which I come across consider predictive ability very strongly. The discovery process with Bayesian networks can also be a lot of fun. Even if one has strong theory, nature is always more clever than we are, and you might find something interesting. See also the <span class="pack">bnpa</span>, <span class="pack">autoSEM</span>, and <span class="pack">regsem</span> packages for more.</p>
</div>
<div id="undirected-graphs" class="section level2">
<h2>Undirected Graphs</h2>
<p>So far we have been discussing directed graphs in which the implied causal flow tends toward one direction and there are no feedback loops. However, sometimes the goal is not so much to estimate the paths as it is to find the structure. <span class="emph">Undirected graphs</span> simply specify the relations of nodes with edges, but without any directed arrows regarding the relationship. Such graphs are sometimes called <span class="emph">Markov Random Fields</span>.</p>
<p>While we could have used the <span class="pack">bnlearn</span> package for an undirected graph by adding the argument <code>undirected = T</code>, there are a slew of techniques available for what is often called <span class="emph">network analysis</span>. Often the focus is on <em>observations</em>, rather than variables, and what influences whether one sees a tie/edge between nodes, with modeling techniques available for predicting ties (e.g. Exponential Random Graph models). Often these are undirected graphs, and that is our focus here, but they do not have to be.</p>
<div id="network-analysis" class="section level3">
<h3>Network analysis</h3>
<p>Networks can be seen everywhere. Personal relationships, machines and devices, various business and academic units… we can analyze the connections among any number of things. A starting point for a very common form of network analysis is an <span class="emph">adjacency matrix</span>, which represents connections among items we wish to analyze. Often it contains just binary 0-1 values where 1 represents a connection between nodes. Any similarity matrix could potentially be used (e.g. a correlation matrix). Here is a simple example of an adjacency matrix:</p>
<table>
<colgroup>
<col width="23%" />
<col width="17%" />
<col width="10%" />
<col width="12%" />
<col width="10%" />
<col width="12%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Bernadette</th>
<th align="center">David</th>
<th align="center">J’Sean</th>
<th align="center">Lagia</th>
<th align="center">Mancel</th>
<th align="center">Nancy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Bernadette</strong></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center"><strong>David</strong></td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center"><strong>J’Sean</strong></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>Lagia</strong></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center"><strong>Mancel</strong></td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>Nancy</strong></td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Visually, we can see the connections among the nodes.</p>
<div id="htmlwidget-a0a192fd039b660ff7af" style="width:672px;height:480px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-a0a192fd039b660ff7af">{"x":{"nodes":{"id":["Bernadette","David","J'Sean","Lagia","Mancel","Nancy"],"label":["Bernadette","David","J'Sean","Lagia","Mancel","Nancy"],"x":[0.0214921151187939,0.186313308217149,-0.602961059855699,1,-1,0.798558550539799],"y":[0.643392418273634,-1,-0.230552820276358,1,0.731257213178948,-0.0345570807764107]},"edges":{"from":["Bernadette","Bernadette","Bernadette","Bernadette","David","David","J'Sean","Lagia"],"to":["J'Sean","Lagia","Mancel","Nancy","J'Sean","Nancy","Mancel","Nancy"]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"physics":false,"shape":"text","color":{"background":"#ff5500","highlight":{"background":"salmon"}},"font":{"size":12,"color":"#FF5500"},"shadow":{"enabled":true,"color":"rgba(0,0,0,0.25)"},"scaling":{"label":{"enabled":true,"min":10,"max":12},"max":5}},"manipulation":{"enabled":false},"edges":{"color":"#00aaff","smooth":{"enabled":true,"forceDirection":"horizontal"}},"physics":{"stabilization":false},"layout":{"randomSeed":123}},"groups":null,"width":null,"height":null,"idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)","igraphlayout":{"type":"square"}},"evals":[],"jsHooks":[]}</script>
<p>As an example of a network analysis, let’s look at how states might be more or less similar on a few variables. We’ll use the <span class="objclass">state.x77</span> data set in base R. It is readily available, no need for loading. To practice your R skills, use the function <span class="func">str</span> on the state.x77 object to examine its structure, and <span class="func">head</span> to see the first 6 rows, and <code>?</code> to find out more about it.</p>
<p>Here are the correlations of the variables.</p>
<div style="width:350px; margin:0 auto;">
<div id="htmlwidget-52d58b974f18f1008288" style="width:350px;height:350px;" class="d3heatmap html-widget"></div>
<script type="application/json" data-for="htmlwidget-52d58b974f18f1008288">{"x":{"rows":null,"cols":null,"matrix":{"data":["1","0.703","-0.781","-0.539","0.344","-0.23","-0.488","0.228","0.703","1","-0.588","-0.672","0.108","-0.437","-0.657","0.077","-0.781","-0.588","1","0.262","-0.068","0.34","0.582","-0.107","-0.539","-0.672","0.262","1","-0.332","0.226","0.367","0.059","0.344","0.108","-0.068","-0.332","1","0.208","-0.098","0.023","-0.23","-0.437","0.34","0.226","0.208","1","0.62","0.363","-0.488","-0.657","0.582","0.367","-0.098","0.62","1","0.334","0.228","0.077","-0.107","0.059","0.023","0.363","0.334","1"],"dim":[8,8],"rows":["Murder","Illiteracy","Life Exp","Frost","Population","Income","HS Grad","Area"],"cols":["Murder","Illiteracy","Life Exp","Frost","Population","Income","HS Grad","Area"]},"image":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAABBUlEQVQYlQXBMUsCcRjA4RdxOFwLh4TaavRP4BC0CG1R1J4tjQd9gwj8Co0RmBR4UBBUUxCcFIEnZzQc2XCcekopiuctR3b363lEUzr5kyfMbI6oVKRm+8Smwfx4l4Y7JbW2syft+ztZLyzJz0dfNlYWhedHGb1+yfJCRsTM5gi3C2hKp96ewNDDaPXZP7dIeg4SlYp08qvU2xM0pRNXylhuwKXVZRTOkZrt0xlHMPSIK2U0pWN7MxL/kzBKkNg0+Ds9xGj1sdwA25uhKZ2tszeqzS6p5PZahg8NqTUH4owDUemBbB4dyMvFlWTSaZGGO+U7+CXpOYzCOWGUUG12uXkfoCmdf0sDrLlVQoGHAAAAAElFTkSuQmCC","theme":null,"options":{"xaxis_height":80,"yaxis_width":120,"xaxis_font_size":null,"yaxis_font_size":null,"brush_color":"#0000FF","show_grid":true,"anim_duration":500,"yclust_width":0,"xclust_height":0}},"evals":[],"jsHooks":[]}</script>
</div>
<p><br></p>
<p>The following depicts a graph of the states based on the variables of Life Expectancy, Median Income, High School Graduation Rate, and Illiteracy. The colors represent the results of a community detection algorithm, and serve to show that the clustering is not merely geographical, though one cluster is clearly geographically oriented (‘the South’).</p>
<div id="htmlwidget-84557a0b36860a8eefc7" style="width:768px;height:480px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-84557a0b36860a8eefc7">{"x":{"nodes":{"id":["Arkansas","Georgia","Kentucky","Louisiana","Mississippi","North Carolina","South Carolina","Tennessee","West Virginia","Delaware","Florida","Massachusetts","Michigan","New York","Pennsylvania","Texas","Virginia","Colorado","Connecticut","Iowa","Kansas","Minnesota","Nebraska","New Jersey","Oregon","Washington","Wyoming","Idaho","Montana","New Hampshire","Utah","Wisconsin","North Dakota","Illinois","Indiana","Maryland","Missouri","Ohio","Oklahoma","Rhode Island","Maine","South Dakota","Vermont","Alaska","Hawaii","Alabama","Arizona","California","Nevada","New Mexico"],"group":[2,2,2,2,2,2,2,2,2,3,3,1,3,3,3,2,3,1,1,1,1,1,1,3,1,1,1,1,1,1,1,1,1,3,3,3,3,3,3,3,3,1,1,4,5,2,3,1,1,2],"size":[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20],"font.size":[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30],"label":["Arkansas","Georgia","Kentucky","Louisiana","Mississippi","North Carolina","South Carolina","Tennessee","West Virginia","Delaware","Florida","Massachusetts","Michigan","New York","Pennsylvania","Texas","Virginia","Colorado","Connecticut","Iowa","Kansas","Minnesota","Nebraska","New Jersey","Oregon","Washington","Wyoming","Idaho","Montana","New Hampshire","Utah","Wisconsin","North Dakota","Illinois","Indiana","Maryland","Missouri","Ohio","Oklahoma","Rhode Island","Maine","South Dakota","Vermont","Alaska","Hawaii","Alabama","Arizona","California","Nevada","New Mexico"],"x":[-0.532155307063252,-0.504654416372245,-0.65122880263121,-0.278812355213636,-0.100980738937185,-0.463893509347421,-0.251086613862349,-0.633648187949715,-0.636438904929209,-0.100093596008548,-0.0970661111906618,0.126969977233815,-0.00479761576797866,-0.164764584280806,-0.0400496471252584,-0.698441295869571,-0.241278415228003,0.419672701331097,0.34226026534528,0.338008680013256,0.402736440655629,0.469067241926949,0.378439840613666,-0.0721588034614804,0.316511031588148,0.25661272261661,0.200485384649041,0.374578929255043,0.174674081102814,0.221197414417377,0.614115548885486,0.233815920324356,0.244461039592015,-0.15207060090688,0.0868977383040654,-0.267064964744546,0.0279918907545795,0.0878455929846063,0.106813458680807,-0.0199910971929096,0.191593762390236,0.269834540182001,0.323408457562345,1,0.692436651289023,-0.400344787870719,-0.323733860312336,0.165822313043993,0.304343314658392,-1],"y":[0.606126182526321,0.854255283297181,0.782998584596074,1,0.940901413705779,0.709217230327315,0.860485413021286,0.549902731999179,0.696007019902068,-0.496732653919545,-0.3646010234255,-0.298183062351367,-0.360090157998461,-0.300738492922996,-0.460812765063497,0.127496540314211,-0.381253449688539,-0.209619380641985,-0.0790618219401729,-0.236057840219671,-0.34027484793603,-0.251751700619159,-0.28460354928898,-0.206038493732906,-0.328380091748613,-0.22955832396963,-0.550423064089746,-0.450154471987675,-0.449066370670961,-0.412757984187484,-0.324823270592737,-0.310906600252156,-0.0685743994847857,-0.486725640668005,-0.429321526706858,-0.471224600405148,-0.532727629714388,-0.383028373064503,-0.562387576566904,-0.25010426765929,-0.672816384149798,-0.500797338563031,-0.477135722715388,0.611578101730956,0.859721199690848,0.793903038991903,-0.225169514092881,-0.173312058660432,-1,0.065110816999727]},"edges":{"from":["Arkansas","Georgia","Kentucky","Louisiana","Mississippi","North Carolina","South Carolina","Tennessee","West Virginia","Delaware","Florida","Massachusetts","Michigan","New York","Pennsylvania","Texas","Virginia","Arkansas","Arkansas","Arkansas","Arkansas","Colorado","Connecticut","Florida","Iowa","Kansas","Massachusetts","Michigan","Minnesota","Nebraska","New Jersey","New York","Oregon","Washington","Wyoming","Colorado","Colorado","Colorado","Colorado","Massachusetts","Colorado","Colorado","Colorado","Colorado","Colorado","Colorado","Colorado","Colorado","Colorado","Connecticut","Connecticut","Massachusetts","Connecticut","Connecticut","Connecticut","Connecticut","Connecticut","Connecticut","Connecticut","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Delaware","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Florida","Georgia","Georgia","Georgia","Georgia","Georgia","Georgia","Idaho","Iowa","Kansas","Idaho","Massachusetts","Minnesota","Idaho","Idaho","Nebraska","Idaho","Idaho","Idaho","Oregon","Idaho","Idaho","Idaho","Washington","Idaho","Wyoming","Illinois","Illinois","Massachusetts","Michigan","Illinois","Montana","New Jersey","New York","Illinois","Pennsylvania","Virginia","Wyoming","Iowa","Kansas","Indiana","Indiana","Massachusetts","Michigan","Indiana","Montana","Nebraska","New Hampshire","New Jersey","New York","Indiana","Indiana","Oregon","Pennsylvania","Indiana","Indiana","Indiana","Virginia","Washington","Wisconsin","Wyoming","Iowa","Massachusetts","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Iowa","Massachusetts","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kansas","Kentucky","Kentucky","Kentucky","Louisiana","Louisiana","Missouri","Montana","New Hampshire","Ohio","Oklahoma","Pennsylvania","Maine","Maine","Michigan","New Jersey","New York","Maryland","Pennsylvania","Virginia","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Massachusetts","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Michigan","Minnesota","Minnesota","Minnesota","Minnesota","Minnesota","Minnesota","Minnesota","Minnesota","Minnesota","Mississippi","Montana","New Hampshire","New York","Missouri","Missouri","Pennsylvania","Missouri","Missouri","Missouri","Virginia","Wisconsin","Nebraska","Montana","Montana","Montana","Oregon","Pennsylvania","Montana","Montana","Washington","Montana","Wyoming","Nebraska","Nebraska","Nebraska","Nebraska","Nebraska","Nebraska","Nebraska","Nebraska","Nebraska","Wyoming","New Hampshire","New Hampshire","Oregon","Pennsylvania","New Hampshire","New Hampshire","Washington","New Hampshire","Wyoming","New York","New Jersey","New Jersey","Pennsylvania","New Jersey","Virginia","Texas","New York","New York","New York","New York","North Carolina","North Carolina","North Carolina","Oregon","North Dakota","Wisconsin","Ohio","Oregon","Pennsylvania","Ohio","Ohio","Ohio","Virginia","Washington","Wisconsin","Wyoming","Pennsylvania","Oklahoma","Oklahoma","Oklahoma","Wisconsin","Oregon","Oregon","Oregon","Oregon","Oregon","Oregon","Pennsylvania","Pennsylvania","Pennsylvania","Pennsylvania","Virginia","Wisconsin","South Dakota","Wisconsin","Tennessee","Tennessee","Utah","Wisconsin","Wyoming","Washington","Washington","Alaska","Hawaii"],"to":["Alabama","Alabama","Alabama","Alabama","Alabama","Alabama","Alabama","Alabama","Alabama","Arizona","Arizona","Arizona","Arizona","Arizona","Arizona","Arizona","Arizona","Kentucky","North Carolina","Tennessee","West Virginia","California","California","California","California","California","California","California","California","California","California","California","California","California","California","Connecticut","Idaho","Iowa","Kansas","Colorado","Minnesota","Montana","Nebraska","New Hampshire","Oregon","Utah","Washington","Wisconsin","Wyoming","Iowa","Kansas","Connecticut","Minnesota","Nebraska","New Jersey","North Dakota","Oregon","Washington","Wisconsin","Florida","Illinois","Indiana","Maryland","Massachusetts","Michigan","Missouri","Montana","New Hampshire","New Jersey","New York","Ohio","Pennsylvania","Virginia","Wyoming","Illinois","Indiana","Maryland","Massachusetts","Michigan","Missouri","Montana","New Hampshire","New Jersey","New York","Ohio","Oklahoma","Pennsylvania","Rhode Island","Virginia","Kentucky","Louisiana","North Carolina","South Carolina","Tennessee","West Virginia","Indiana","Idaho","Idaho","Maine","Idaho","Idaho","Missouri","Montana","Idaho","New Hampshire","Ohio","Oklahoma","Idaho","South Dakota","Utah","Vermont","Idaho","Wisconsin","Idaho","Indiana","Maryland","Illinois","Illinois","Missouri","Illinois","Illinois","Illinois","Ohio","Illinois","Illinois","Illinois","Indiana","Indiana","Maine","Maryland","Indiana","Indiana","Missouri","Indiana","Indiana","Indiana","Indiana","Indiana","Ohio","Oklahoma","Indiana","Indiana","Rhode Island","South Dakota","Vermont","Indiana","Indiana","Indiana","Indiana","Kansas","Iowa","Minnesota","Montana","Nebraska","New Hampshire","North Dakota","Ohio","Oregon","South Dakota","Utah","Vermont","Washington","Wisconsin","Kansas","Minnesota","Montana","Nebraska","New Hampshire","North Dakota","Ohio","Oregon","South Dakota","Utah","Vermont","Washington","Wisconsin","North Carolina","Tennessee","West Virginia","Mississippi","South Carolina","Maine","Maine","Maine","Maine","Maine","Maine","South Dakota","Vermont","Maryland","Maryland","Maryland","Ohio","Maryland","Maryland","Michigan","Minnesota","Montana","Nebraska","New Hampshire","New Jersey","New York","North Dakota","Ohio","Oklahoma","Oregon","Pennsylvania","Rhode Island","South Dakota","Vermont","Washington","Wisconsin","Wyoming","Missouri","Montana","New Hampshire","New Jersey","New York","Ohio","Oklahoma","Oregon","Pennsylvania","Rhode Island","South Dakota","Virginia","Washington","Wisconsin","Wyoming","Nebraska","New Hampshire","North Dakota","Oregon","South Dakota","Utah","Vermont","Washington","Wisconsin","South Carolina","Missouri","Missouri","Missouri","Ohio","Oklahoma","Missouri","Rhode Island","South Dakota","Vermont","Missouri","Missouri","Montana","New Hampshire","Ohio","Oklahoma","Montana","Montana","South Dakota","Vermont","Montana","Wisconsin","Montana","New Hampshire","North Dakota","Ohio","Oregon","South Dakota","Utah","Vermont","Washington","Wisconsin","Nevada","Ohio","Oklahoma","New Hampshire","New Hampshire","South Dakota","Vermont","New Hampshire","Wisconsin","New Hampshire","New Jersey","North Dakota","Ohio","New Jersey","Rhode Island","New Jersey","New Mexico","Ohio","Pennsylvania","Rhode Island","Virginia","South Carolina","Tennessee","West Virginia","North Dakota","Rhode Island","North Dakota","Oklahoma","Ohio","Ohio","Rhode Island","South Dakota","Vermont","Ohio","Ohio","Ohio","Ohio","Oklahoma","Rhode Island","South Dakota","Vermont","Oklahoma","South Dakota","Utah","Vermont","Washington","Wisconsin","Wyoming","Rhode Island","South Dakota","Vermont","Virginia","Rhode Island","Rhode Island","Vermont","South Dakota","Texas","West Virginia","Vermont","Vermont","Vermont","Wisconsin","Wyoming","Alaska","Hawaii"],"Value":[0.7588783174158,1.14982664979011,0.837592972096204,0.846824261156591,0.819831632736631,1.35646303205178,1.02324991651013,0.928160400883504,0.838300768501751,0.607754498962246,0.857992063075157,0.650310728478488,0.603719582194316,0.895821281670155,0.608060156173552,0.624589022999154,0.665649413353595,1.16109087028113,0.72973128918655,1.08425070264559,0.780591788037889,1.22661018167582,0.935867558827191,0.633838135876759,0.675101994100898,0.760476470030003,1.28352499978478,0.623046804444444,0.641024680626414,0.666370054542809,0.717708145461872,0.619077001947045,0.839092849385397,1.08408207009545,0.621538890814545,0.697511643211395,0.726687249417125,1.12651111320719,1.35500327234262,1.0254064965153,0.91268511452882,0.648494776194366,1.06147862490693,0.715436907749723,1.58976221966619,0.624558559114521,3.25166102094108,0.723450541222127,0.698665689909551,0.634559259865933,0.684762611412393,0.890305028274032,0.700214096904547,0.606719854895907,0.802279894107659,1.01501844978136,0.668186590765568,0.635503686473702,0.630424734127577,1.20225999445818,1.82555219785093,1.08376284728264,1.16945297525257,0.692198017628526,2.04605733234857,0.795904553835413,0.88713633574622,0.757309815832148,0.962049407960515,1.0630664428047,1.36034713137372,1.16021256935377,0.841318009740337,0.820894880048205,1.11350168473041,0.865565507851196,0.928520450357468,0.842023475011092,1.50310231265107,0.76066604124445,0.623514681696444,0.661149470515559,1.27007838695649,4.29166457365573,1.07614840187534,0.66272118622236,1.18289717074472,0.78629989307651,1.2897227550153,0.669774805782005,0.62278268650515,1.35093349608555,0.95354366956775,0.740183973316051,0.695101064261087,0.80506982909266,1.00957308816268,0.960755749554574,0.694378633376856,0.753689932851513,0.807556416735102,0.610439484322447,0.957221087939255,1.19770420411242,1.62422635814998,0.736153362751813,0.747246211985534,1.1066735332343,1.24349023604244,0.804196751463575,2.05549945861476,0.760787048318593,1.03185603505479,0.691429329686751,0.808856339697302,3.12248296282043,0.62569080684515,1.45940808149423,0.653274839179437,0.627751150528715,1.4157589875571,1.06809985251925,0.962877974960355,0.87417811332454,0.826297956612586,0.613590170182513,0.656416153131992,0.632495784927789,0.760545762533694,0.669929283254805,0.779491486666479,1.64427937344967,1.55259899962482,1.17463358104451,0.658935749403239,1.42921216392397,0.699847721165729,0.724641212138694,4.13835324776803,0.906867480523495,0.75063368227263,1.46399483602508,0.671090888754873,0.939269322853768,0.838613213903359,0.669783075301592,0.622892189093978,0.827568066697398,0.748726357487327,4.7669950920303,0.873291558640894,2.5683332796806,0.638045425536353,3.85410313816772,0.833846158520073,0.709362210014447,0.638890181238812,2.60321967430306,0.917184133859794,0.686856444650992,0.720050548515195,1.06819745239832,1.42942040597487,0.983101298147289,2.48978588294586,0.626658867169439,3.66637973907507,0.811619088294802,0.706173289636165,0.626763888783738,2.97822671932103,0.816281765173939,0.706242643501336,0.682256944127114,1.18695330851489,1.30582777254489,1.27247403540234,2.10647517674461,1.4253918256059,0.901293861418341,0.861857052481459,0.833040547691509,0.821247105845189,0.835348244938594,0.681225712147006,0.848833209855139,0.696186032833233,0.65721319680411,0.952402698516219,1.05853054558893,1.58471196913991,0.932058028927103,0.771151231442774,0.701426713815706,0.717720941686761,0.843699653557764,0.841897592091274,0.704237131539764,0.923197819433264,0.898789560718424,0.786492602809332,0.761363459879501,0.69577367731484,0.864325033486255,0.645291060160842,1.13138692282956,0.643015780778362,0.637911958901117,0.654583836905783,0.616918473045963,0.955948530007539,0.941337578333881,0.648157810595984,1.0378609970346,0.875345167690751,0.895984182641708,1.12898927842747,1.16421797313372,2.62602102485566,0.700446795801299,0.65832200108567,1.59255287004024,0.698053882457244,0.631885429159826,0.901452255325191,0.609672588983899,0.664699957291161,0.714158603889173,2.29365953785649,0.690243896715714,0.847559663112655,1.45682033176443,0.838131315925103,0.623346593550617,0.628335704551335,0.821590669150638,1.55124649032099,1.02221859886894,0.745795306951012,0.851965266438829,0.655327755089639,1.34139863377787,1.08296657210112,1.90371239306965,0.741570404992356,0.779710707987034,0.710064478990376,0.762498142983219,0.64225543207587,0.648447262632704,1.74927112342879,1.10546645346323,0.656587369354757,0.781552035619564,0.764899429499152,0.720108921191107,0.902543133905148,0.758522219351063,0.638876187076685,1.62795151051662,0.894698376438444,0.665907161747982,0.639696292313271,2.28643044883012,0.982109172674993,0.776962511633253,0.805233888962156,0.982569477580044,1.59655358277467,0.727545417884904,1.2653143078977,0.898857895463142,1.02861527696875,0.813374189495579,1.1000004432022,1.42206728162987,0.792072311108613,0.950441344885744,0.927295963604313,1.27160021739983,0.662952856630289,0.825695363057844,0.727142530840117,0.642660191937992,0.757513129273973,0.701542031074858,0.869391177468612,0.962098214000553,0.713938665763945,1.29240465297832,0.766956310473581,1.23933563849256,1.12175119689176,0.664121514756021,0.69388661509974,0.85684625669691,0.8555835805988,0.746449294516663,1.65920023050255,0.702038826688879,0.807253470920464,0.735861530918023,0.751277774476824,0.641960705801096,0.789361599992211,0.765644388542803,0.92214474645947,0.809601152007061,0.862370232715235,0.92106804541266,0.74410082953749,0.857457166262057,0.67056292735172,0.752950759148331,1.59866404750601,1.23445829256661,0.701673205392962,0.768275425767166,0.627255565421346,0.602918547029968,1.15078511630228,0.716247570066059,0.676850842547143,1.36751380745593,1.4768598915857,0.733896669770577,1.32068398586394,0.631091821815602,0.858872943883652,0.611165899054636,0.706333693062254,0.85264885312398,1e-05,1e-05],"weight":[0.7588783174158,1.14982664979011,0.837592972096204,0.846824261156591,0.819831632736631,1.35646303205178,1.02324991651013,0.928160400883504,0.838300768501751,0.607754498962246,0.857992063075157,0.650310728478488,0.603719582194316,0.895821281670155,0.608060156173552,0.624589022999154,0.665649413353595,1.16109087028113,0.72973128918655,1.08425070264559,0.780591788037889,1.22661018167582,0.935867558827191,0.633838135876759,0.675101994100898,0.760476470030003,1.28352499978478,0.623046804444444,0.641024680626414,0.666370054542809,0.717708145461872,0.619077001947045,0.839092849385397,1.08408207009545,0.621538890814545,0.697511643211395,0.726687249417125,1.12651111320719,1.35500327234262,1.0254064965153,0.91268511452882,0.648494776194366,1.06147862490693,0.715436907749723,1.58976221966619,0.624558559114521,3.25166102094108,0.723450541222127,0.698665689909551,0.634559259865933,0.684762611412393,0.890305028274032,0.700214096904547,0.606719854895907,0.802279894107659,1.01501844978136,0.668186590765568,0.635503686473702,0.630424734127577,1.20225999445818,1.82555219785093,1.08376284728264,1.16945297525257,0.692198017628526,2.04605733234857,0.795904553835413,0.88713633574622,0.757309815832148,0.962049407960515,1.0630664428047,1.36034713137372,1.16021256935377,0.841318009740337,0.820894880048205,1.11350168473041,0.865565507851196,0.928520450357468,0.842023475011092,1.50310231265107,0.76066604124445,0.623514681696444,0.661149470515559,1.27007838695649,4.29166457365573,1.07614840187534,0.66272118622236,1.18289717074472,0.78629989307651,1.2897227550153,0.669774805782005,0.62278268650515,1.35093349608555,0.95354366956775,0.740183973316051,0.695101064261087,0.80506982909266,1.00957308816268,0.960755749554574,0.694378633376856,0.753689932851513,0.807556416735102,0.610439484322447,0.957221087939255,1.19770420411242,1.62422635814998,0.736153362751813,0.747246211985534,1.1066735332343,1.24349023604244,0.804196751463575,2.05549945861476,0.760787048318593,1.03185603505479,0.691429329686751,0.808856339697302,3.12248296282043,0.62569080684515,1.45940808149423,0.653274839179437,0.627751150528715,1.4157589875571,1.06809985251925,0.962877974960355,0.87417811332454,0.826297956612586,0.613590170182513,0.656416153131992,0.632495784927789,0.760545762533694,0.669929283254805,0.779491486666479,1.64427937344967,1.55259899962482,1.17463358104451,0.658935749403239,1.42921216392397,0.699847721165729,0.724641212138694,4.13835324776803,0.906867480523495,0.75063368227263,1.46399483602508,0.671090888754873,0.939269322853768,0.838613213903359,0.669783075301592,0.622892189093978,0.827568066697398,0.748726357487327,4.7669950920303,0.873291558640894,2.5683332796806,0.638045425536353,3.85410313816772,0.833846158520073,0.709362210014447,0.638890181238812,2.60321967430306,0.917184133859794,0.686856444650992,0.720050548515195,1.06819745239832,1.42942040597487,0.983101298147289,2.48978588294586,0.626658867169439,3.66637973907507,0.811619088294802,0.706173289636165,0.626763888783738,2.97822671932103,0.816281765173939,0.706242643501336,0.682256944127114,1.18695330851489,1.30582777254489,1.27247403540234,2.10647517674461,1.4253918256059,0.901293861418341,0.861857052481459,0.833040547691509,0.821247105845189,0.835348244938594,0.681225712147006,0.848833209855139,0.696186032833233,0.65721319680411,0.952402698516219,1.05853054558893,1.58471196913991,0.932058028927103,0.771151231442774,0.701426713815706,0.717720941686761,0.843699653557764,0.841897592091274,0.704237131539764,0.923197819433264,0.898789560718424,0.786492602809332,0.761363459879501,0.69577367731484,0.864325033486255,0.645291060160842,1.13138692282956,0.643015780778362,0.637911958901117,0.654583836905783,0.616918473045963,0.955948530007539,0.941337578333881,0.648157810595984,1.0378609970346,0.875345167690751,0.895984182641708,1.12898927842747,1.16421797313372,2.62602102485566,0.700446795801299,0.65832200108567,1.59255287004024,0.698053882457244,0.631885429159826,0.901452255325191,0.609672588983899,0.664699957291161,0.714158603889173,2.29365953785649,0.690243896715714,0.847559663112655,1.45682033176443,0.838131315925103,0.623346593550617,0.628335704551335,0.821590669150638,1.55124649032099,1.02221859886894,0.745795306951012,0.851965266438829,0.655327755089639,1.34139863377787,1.08296657210112,1.90371239306965,0.741570404992356,0.779710707987034,0.710064478990376,0.762498142983219,0.64225543207587,0.648447262632704,1.74927112342879,1.10546645346323,0.656587369354757,0.781552035619564,0.764899429499152,0.720108921191107,0.902543133905148,0.758522219351063,0.638876187076685,1.62795151051662,0.894698376438444,0.665907161747982,0.639696292313271,2.28643044883012,0.982109172674993,0.776962511633253,0.805233888962156,0.982569477580044,1.59655358277467,0.727545417884904,1.2653143078977,0.898857895463142,1.02861527696875,0.813374189495579,1.1000004432022,1.42206728162987,0.792072311108613,0.950441344885744,0.927295963604313,1.27160021739983,0.662952856630289,0.825695363057844,0.727142530840117,0.642660191937992,0.757513129273973,0.701542031074858,0.869391177468612,0.962098214000553,0.713938665763945,1.29240465297832,0.766956310473581,1.23933563849256,1.12175119689176,0.664121514756021,0.69388661509974,0.85684625669691,0.8555835805988,0.746449294516663,1.65920023050255,0.702038826688879,0.807253470920464,0.735861530918023,0.751277774476824,0.641960705801096,0.789361599992211,0.765644388542803,0.92214474645947,0.809601152007061,0.862370232715235,0.92106804541266,0.74410082953749,0.857457166262057,0.67056292735172,0.752950759148331,1.59866404750601,1.23445829256661,0.701673205392962,0.768275425767166,0.627255565421346,0.602918547029968,1.15078511630228,0.716247570066059,0.676850842547143,1.36751380745593,1.4768598915857,0.733896669770577,1.32068398586394,0.631091821815602,0.858872943883652,0.611165899054636,0.706333693062254,0.85264885312398,1e-05,1e-05]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot","physics":false},"manipulation":{"enabled":false},"edges":{"smooth":false},"physics":{"stabilization":false}},"groups":["2","3","1","4","5"],"width":null,"height":null,"idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)","igraphlayout":{"type":"full"}},"evals":[],"jsHooks":[]}</script>
<div id="understanding-networks" class="section level4">
<h4>Understanding Networks</h4>
<p>Networks can be investigated in an exploratory fashion or lead to more serious modeling approaches. The following is a brief list of common statistics or modeling techniques.</p>
<div id="centrality" class="section level5">
<h5>Centrality</h5>
<ul>
<li><strong>Degree</strong>: how many links a node has (can also be ‘in-degree’ or ‘out-degree’ for directed graphs)</li>
<li><strong>Closeness</strong>: how close a node is to other nodes</li>
<li><strong>Betweenness</strong>: how often a node serves as a bridge between the shortest path between two other nodes</li>
<li><strong>PageRank</strong>: From Google, a measure of node ‘importance’</li>
<li><strong>Hub</strong>: a measure of the value of a node’s links</li>
<li><strong>Authority</strong>: another measure of node importance</li>
</ul>
<p>Characteristics of the network as a whole may also be examined, e.g. degree distribution, ‘clusteriness’, average path length etc.</p>
</div>
<div id="cohesion" class="section level5">
<h5>Cohesion</h5>
<p>One may wish to investigate how network members create communities and cliques. This is similar to standard cluster analysis used in other situations. Some nodes may be isolated.</p>
</div>
<div id="modeling" class="section level5">
<h5>Modeling</h5>
<ul>
<li>ERGM: exponential random graph models, regression modeling for network data</li>
<li>Other ‘link’ analysis</li>
</ul>
</div>
<div id="comparison" class="section level5">
<h5>Comparison</h5>
<p>A goal might be to compare multiple networks to see if they differ in significant ways.</p>
</div>
<div id="dynamics" class="section level5">
<h5>Dynamics</h5>
<p>While many networks are ‘static’, many others change over time. One might be interested in this structural change by itself, or modeling something like link loss. See the <span class="pack">ndtv</span> package for some nice visualization of such approaches.</p>
</div>
</div>
</div>
</div>
<div id="summary-1" class="section level2">
<h2>Summary</h2>
<p>Graphical models are a general way to formulate and visualize statistical models. <em>All</em> statistical models can be developed within this framework. Structured causal models provide a means to posit causal thinking with graphical models, and structural equation models may be seen as a subset of those. Path analysis within SEM is a form of theoretically motivated graphical model involving only observed variables. These models might include indirect effects and multiple outcomes of interest, and can be seen as an extension of more familiar regression models to such settings. However, path analysis is just one of a broad set of graphical modeling tools widely used in many disciplines, any of which might be useful for a particular data situation.</p>
</div>
<div id="r-packages-used" class="section level2">
<h2>R packages used</h2>
<ul>
<li><span class="pack">lavaan</span></li>
<li><span class="pack">mediation</span></li>
<li><span class="pack">bnlearn</span></li>
<li><span class="pack">network</span></li>
</ul>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>There are other assumptions at work also, e.g. that the model is correct and there are no other confounders.<a href="graphical-models-1.html#fnref1">↩</a></p></li>
<li id="fn2"><p>Sewall Wright first used path analysis almost 100 years ago.<a href="graphical-models-1.html#fnref2">↩</a></p></li>
<li id="fn3"><p>I use <em>multivariate</em> here to refer to multiple dependent variables, consistent with <em>multivariate analysis</em> generally. Some use it to mean multiple predictors, but since you’re not going to see single predictor regression outside of an introductory statistical text, there is no reason to distinguish it. Same goes for <em>multiple</em> regression.<a href="graphical-models-1.html#fnref3">↩</a></p></li>
<li id="fn4"><p>Note this is just a syntax shortcut to running multiple models, not an actual ‘multivariate’ analysis.<a href="graphical-models-1.html#fnref4">↩</a></p></li>
<li id="fn5"><p>In the past people would run separate OLS regressions to estimate mediation models, particularly for the most simple, three variable case. One paper that for whatever reason will not stop being cited is Baron &amp; Kenny 1986. <em>It was 1986</em>. Please do not do mediation models like this. You will always have more than three variables to consider, and always have access to R or other software that can estimate the model appropriately. While I think it is very helpful to estimate your models in piecemeal fashion for debugging purposes and to facilitate your understanding, use appropriate tools for the model you wish to estimate. Some packages, such as <span class="pack">mediate</span>, may still require separate models, but there is far more going on ‘under the hood’ even then. For more recent work in this area, see the efforts of <a href="http://bayes.cs.ucla.edu/jp_home.html">Pearl</a> and <a href="http://imai.princeton.edu/research/index.html">Imai</a> especially.<a href="graphical-models-1.html#fnref5">↩</a></p></li>
<li id="fn6"><p>I’ve seen some balk at this sort of description, but the fact remains that SEM does not have any more tie to causality than any other statistical tool, other than what applied researchers ascribe to their results. As mentioned before, SEM does not discover causality or allow one to make causal statements simply by conducting it. It’s just a statistical model.<a href="graphical-models-1.html#fnref6">↩</a></p></li>
<li id="fn7"><p>I suspect this is likely the case for the majority of modeling scenarios in social sciences that are often dealing with fairly weak effects, where the additional complexity would typically not result in better predictive value.<a href="graphical-models-1.html#fnref7">↩</a></p></li>
<li id="fn8"><p>There is a statement “All results controlled for background covariates of vocabulary at age 4, gender, adoption status, and maternal education level.” and a picture of only the three-variable mediation model. If you are surprised at this lack of information, you may not be familiar with the field of psychological research.<a href="graphical-models-1.html#fnref8">↩</a></p></li>
<li id="fn9"><p>The historical reference for this approach is with Rubin and even earlier with Neyman. Some may make the distinction between potential outcomes, which are <em>potentially</em> observable for everyone, and counterfactuals that are inherently unobservable.<a href="graphical-models-1.html#fnref9">↩</a></p></li>
<li id="fn10"><p>See the package <a href="ftp://cran.r-project.org/pub/R/web/packages/mediation/vignettes/mediation.pdf">vignette</a> and Imai’s <a href="http://imai.princeton.edu/projects/mechanisms.html">papers</a> for more detail<a href="graphical-models-1.html#fnref10">↩</a></p></li>
<li id="fn11"><p>In general, the recommendation is to use bootstrap estimates for the indirect effect interval estimate anyway.<a href="graphical-models-1.html#fnref11">↩</a></p></li>
<li id="fn12"><p>Pearl devised a <em>do operator</em>, e.g. <span class="math inline">\(p(y|\textrm{do}(\mathcal{X}))\)</span>, where given some model, we can assess results as if ‘<span class="math inline">\(\mathcal{X}\)</span> had been <span class="math inline">\(x_0\)</span>’, i.e. holding <span class="math inline">\(\mathcal{X}\)</span> at some value. The gist is that taking the appropriate modeling steps will allow us to investigate questions such as ‘if X had been something else’, i.e. a counterfactual.<a href="graphical-models-1.html#fnref12">↩</a></p></li>
<li id="fn13"><p>Bollen &amp; Pearl (2013) list myth #2 about SEM is that SEM and regression are essentially equivalent. While I agree that we can think of them differently, I don’t find their exposition very persuasive. Their explanation of a structural model is no different than what you see for standard regression in econometrics and more rigorous statistics books. It’s not clear to me where they think a ‘residual’ in regression comes from if not from ‘unexplained causes’ not included in the model (I actually prefer stating regression models as <span class="math inline">\(y \sim \mathcal{N}(X\beta, \sigma^2)\)</span> so as to make the data generating process explicit, a point mostly ignored in SEM depictions). Changing to ‘equals’ (=) to ‘assignment’ (:=) in the equation doesn’t work if you consider that most programming languages use = for assignment. Adding a picture certainly doesn’t change things, and as a consultant, I can say that expressing a model graphically first doesn’t keep people from positing models that are very problematic from a causal perspective (and may actually encourage it). <br><br> The gist is that causality is something the researcher, not the data or the model, brings to the scientific table in an explicit fashion, something Bollen &amp; Pearl even state clearly in their discussion of the first myth (that SEM aims to establish causal relations from correlations). Practically speaking, an SEM will produce exactly the same output whether you have strong causal claims or not.<a href="graphical-models-1.html#fnref13">↩</a></p></li>
<li id="fn14"><p>As an example, see if you can think of a situation in which an interaction between two variables on some outcome, which technically represents a <em>difference</em> in coefficient values, would only exist indirectly. Also realize that simply positing such a situation for two variables would mean you’d have to rule out several competing models of all possible direct and indirect paths between A, B, and their product term. Just for giggles you might also consider that either A or B might have more than two categories, and so must be represented by multiple dummy coded variables and multiple interaction terms. Have fun!<a href="graphical-models-1.html#fnref14">↩</a></p></li>
<li id="fn15"><p>Kline distinguishes indirect effects vs. mediation. I don’t, because I don’t believe SEM to have any inherently greater ability to discern causality than any other framework, and it doesn’t. I do like his suggestion that mediation be reserved for effects involving time precedence, and defaulting to ‘indirect effects’ should keep you out of trouble. But even then, and as physics dictates, the arrow of time is inconsequential on a macro level. All else being equal, your model will fit as well with time 2 <span class="math inline">\(\rightarrow\)</span> time 1 as time 2 <span class="math inline">\(\leftarrow\)</span> time 1.<a href="graphical-models-1.html#fnref15">↩</a></p></li>
<li id="fn16"><p>Along with the notion of <em>buffering</em>, which is a near useless term in my opinion.<a href="graphical-models-1.html#fnref16">↩</a></p></li>
<li id="fn17"><p>See for example, Wu &amp; Zumbo (2008) Understanding and using mediators and moderators. (<a href="http://link.springer.com/article/10.1007/s11205-007-9143-1">link</a>)<a href="graphical-models-1.html#fnref17">↩</a></p></li>
<li id="fn18"><p>Unless you want to signal to people who are statistically knowledgeable that they should stop paying attention to your work. In general, it’s probably best to avoid using the applied literature as a basis for how to conduct or report methods. While excellent examples may be found, many fields have typically ignored their own quantitative methodologists and statisticians for decades. Psychology is rather notorious in this regard, while I might point to political science as a counter example, in the sense that the latter has long had one of its most popular journals a methodological one.<a href="graphical-models-1.html#fnref18">↩</a></p></li>
<li id="fn19"><p>In Pearl’s language, Z is d-separated from Y if the X -&gt; Y path is removed, but not d-separated from X. The <em>d</em> stands for <em>directional</em>.<a href="graphical-models-1.html#fnref19">↩</a></p></li>
<li id="fn20"><p>Some of this example comes from Cameron and Trivedi’s <em>Microeconometrics</em>, which has a pretty clean (in my opinion) depiction of instrumental variable analysis.<a href="graphical-models-1.html#fnref20">↩</a></p></li>
<li id="fn21"><p>I’m curious how common it is that you would have enough fully complete X, but no Y to even model the missingness. The usual situation I see is either complete missingness or, far more commonly, missingness all over the data, which means you’d have to model the missingness in X in order to model they Y. In other words, you’d have a general missingness problem to consider to even be able to do the initial probit model. Stuff like this seems endemic to instrumental variable analysis. In the standard IV model, it’s all well and good, <em>if you have an instrument</em>. But as previously mentioned, no one collects data thinking about getting some instrumental variables <em>just in case</em>, and if you don’t get it right, which is impossible to tell, you’ve likely opened up any number of back doors in a causal sense. And if you think economists have it all figured out, do a search on ‘rainfall’ ‘tv’ and ‘autism’, or perhaps just use common sense and know those three things should not go together in a model.<a href="graphical-models-1.html#fnref21">↩</a></p></li>
<li id="fn22"><p>Economists are like Vogons. They do good work, efficient, consistent, and without bias, but in the end no one wants anything to do with their poetry.<a href="graphical-models-1.html#fnref22">↩</a></p></li>
<li id="fn23"><p>No, ‘non’-recursive as a name for these models makes no sense to me either.<a href="graphical-models-1.html#fnref23">↩</a></p></li>
<li id="fn24"><p>Note that if this approach were able to uncover causal relations via statistical means, a blacklist would not be necessary. If you actually tried it here, you’d find adoption status influenced by early adult scholastic abilities.<a href="graphical-models-1.html#fnref24">↩</a></p></li>
<li id="fn25"><p>I have no bone to pick nor know the authors, but after seeing the models thus far, at this point I have to question the major conclusion of the McClelland et al. paper, which focuses on the effects of attention span on these outcomes, and concludes the indirect effects are notable and that there is a noteworthy direct effect on math at age 21. To begin, the attention span variable starts with no strong linear correlation with either outcome. They admit no direct effect on reading, but then suggest there is still an indirect effect even though it is practically zero and the bulk of it clearly is the read7 <span class="math inline">\(\rightarrow\)</span> read21 path. If demographics only predict read21 (again this isn’t clear from their paper, but such a model does duplicate the few values they actually report), then the R<sup>2</sup> for read7 is ~ 1.6%. Thus I can’t think of any way to conclude a direct or indirect effect of attention span at age 4 on reading at 21. The math results are only marginally better, but even there the internal fit indices are poor (e.g. RMSEA etc.). Had a model comparison approach been used, AIC would not have chosen the mediation model in either case. <br><br> In general, if the path from a variable to a potential mediator is essentially zero to begin with, save yourself some trouble- there is no reason to test for indirect effects (zero times any value is still zero).<a href="graphical-models-1.html#fnref25">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="latent-variables-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "san-serif",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "chapter",
"depth": 3
},
"highlight": "pygments",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
